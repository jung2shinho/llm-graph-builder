{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Background**\n",
    "## **Knowledge Graph Evaluation and Metrics**\n",
    "This notebook seeks to identify the different points of evaluation for developing knowledege graphs, in order to establish metrics for evaluating response performance. Below lists the three different stages of RAG where each stage identifies specific control points for adjusting configuration and input parameters for improving RAG performance.\n",
    "\n",
    "## **Neo4j and Three Stages of GraphRAG**\n",
    "Neo4j is a graph database management system that is designed to handle large amounts of data in the form of graphs. Unlike traditional relational databases, Neo4j utilizes graph structures consisting of nodes, edges (relationships), and properties. Cypher Query language is utilized for retrieving the relevant nodes from a graph based on the modes and initial configurations set for the retrieval process. \n",
    "\n",
    "The three stages of GraphRAG are:\n",
    "1. Ingestion and Preprocessing\n",
    "2. Retrieval\n",
    "3. Response\n",
    "\n",
    "Each stage have various input and configuration parameters that can affect RAG performance and its metrics. \n",
    "\n",
    "The functions are based on the public [Neo4j llm-graph-builder repo](!https://github.com/neo4j-labs/llm-graph-builder)\n",
    "\n",
    "### **Quick Guide**\n",
    "If you're looking to test various queries and see how different modes of retrievals outputs a response, then follow the following steps:\n",
    "\n",
    "1. Change the ```question``` to test different queries\n",
    "2. Restart Kennel and Run all\n",
    "3. Look at the **Comparisons** cell for response results (2nd to last cell)\n",
    "\n",
    "*References*: \n",
    "- [Neo4j llm-graph-builder Github repo](https://github.com/neo4j-labs/llm-graph-builder)\n",
    "- [RAG TRIAD Metrics](https://truera.com/ai-quality-education/generative-ai-rags/what-is-the-rag-triad/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Initial Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add path to sys.path to enable methods within backend/src (do at least once)\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "sys.path.append('/home/shinhojung/llm-graph-builder/backend')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"example.env\")\n",
    "\n",
    "# print(sys.path)\n",
    "# print(os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ingestion and Preprocessing**\n",
    "The ingestion method for this demo utilizes the [Neo4j App](https://llm-graph-builder.neo4jlabs.com/) for uploading and processing the unstructured data (i.e PDF), which is outside of this Juypter Notebook. Through the Neo4j App, data is chunked into smaller, managable pieces with overlapping, predefined fixed-length parameters. Then each chunk is processed through an LLM (i.e chatGPT, gemini) under its Named Entity Recognition (NER) capability to create nodal entities and their associated relationships. Once these entities are created, an embedding model creates vector embeddings of each node, capturing semantic meaning of the entity and its surrounding text, and then stores these vector embeddings as a property of the respective nodes.\n",
    "\n",
    "**NOTE**: All chunk nodes are created and connected to an associated document node.\n",
    "\n",
    "**Levers of Control:**\n",
    "- **Schema & Chunk Tailoring**\n",
    "  - Predefined schema can help identiify specific entities and relationships that are more suitable and oriented to the targeted domain or application, affecting the overall RAG graph search and document retrieval methods.\n",
    "  - Neo4j has a default schema during ingestion and preprocessing.\n",
    "- **Embedding Model Assessment**\n",
    "  - Different emedding models (i.e all-MiniLM-L6-v2) provide different numeric values in vector embeddings affecting similarity search results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Connecting with a Neo4j DB instance**\n",
    "Run the backend of the llm-graph-builder repo by running the following command within the ```llm-graph-builder/backend``` folder:\n",
    "\n",
    "```uvicorn score:app --reload --log-level debug```\n",
    "\n",
    "This runs a local server that enables API defined by the ```llm-graph-builder``` public repo. \n",
    "\n",
    "**NOTE**: This assumes there's an existing Neo4j instance already created with a graph using the Neo4j app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"status\":\"Success\",\"data\":{\"db_vector_dimension\":384,\"application_dimension\":384,\"message\":\"Connection Successful\"}}\n"
     ]
    }
   ],
   "source": [
    "# Connect with Neo4j Database @/connect\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Define Neo4j Database connection\n",
    "\n",
    "## Anatomy & Physiology\n",
    "uri=\"neo4j+s://819c2e86.databases.neo4j.io:7687\"\n",
    "userName=\"neo4j\"\n",
    "password=\"3rLOPhwRVsZa6zzv7Nl0EusFB2Rocl_OTH34UIUeayw\"\n",
    "database=\"neo4j\"\n",
    "\n",
    "# # Compliance knowledge Graph\n",
    "# uri=\"neo4j+s://db5d18b3.databases.neo4j.io:7687\"\n",
    "# userName=\"neo4j\"\n",
    "# password=\"MHCzaBJ3OPoDIKeJyuxVWNiWqGUVmB5s5BEHUw4KvCA\"\n",
    "# database=\"neo4j\"\n",
    "\n",
    "\n",
    "url = \"http://127.0.0.1:8000/connect\"\n",
    "\n",
    "data = {\n",
    "    \"uri\": uri,\n",
    "    \"userName\": userName,\n",
    "    \"password\":password,\n",
    "    \"database\":database\n",
    "}\n",
    "\n",
    "content_length = len(data)\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "    \"Content-Length\":\"4\"\n",
    "}\n",
    "json_data = json.dumps(data)\n",
    "\n",
    "response = requests.post(url, headers=headers, data=data)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualize Graph in Juypter Notebooks using yfiles**\n",
    "Compare the yfiles widget graph display with Neo4j's online [visualization tool](!https://llm-graph-builder.neo4jlabs.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64fe8a3170fb438289f4228d5634fc55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='800px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize Graph\n",
    "from neo4j import GraphDatabase\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "\n",
    "default_cypher = \"MATCH (n:Document)<-[r]->(c:Chunk)<-[s]->(e) RETURN n,r,c,s,e LIMIT 100\"\n",
    "\n",
    "def showGraph(cypher: str = default_cypher):\n",
    "    driver = GraphDatabase.driver(\n",
    "        uri = uri,\n",
    "        auth = (os.environ[\"NEO4J_USERNAME\"], os.environ[\"NEO4J_PASSWORD\"])\n",
    "    )\n",
    "    session = driver.session()\n",
    "    widget = GraphWidget(graph = session.run(cypher).graph())\n",
    "    widget.node_label_mapping = 'id'\n",
    "    return widget\n",
    "\n",
    "showGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Find number of nodes and relationships in Knowledge Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (d) { ... }} {position: line: 6, column: 1, offset: 155} for query: '\\nMATCH docs = (d:Document) \\nWHERE d.fileName IN $document_names\\nWITH docs, d ORDER BY d.createdAt DESC\\n// fetch chunks for documents, currently with limit\\nCALL {\\n  WITH d\\n  OPTIONAL MATCH chunks=(d)<-[:PART_OF|FIRST_CHUNK]-(c:Chunk)\\n  RETURN c, chunks LIMIT 50\\n}\\n\\nWITH collect(distinct docs) as docs, collect(distinct chunks) as chunks, collect(distinct c) as selectedChunks\\nWITH docs, chunks, selectedChunks\\n// select relationships between selected chunks\\nWITH *, \\n[ c in selectedChunks | [p=(c)-[:NEXT_CHUNK|SIMILAR]-(other) WHERE other IN selectedChunks | p]] as chunkRels\\n\\n// fetch entities and relationships between entities\\nCALL {\\n  WITH selectedChunks\\n  UNWIND selectedChunks as c\\n  \\n  OPTIONAL MATCH entities=(c:Chunk)-[:HAS_ENTITY]->(e)\\n  OPTIONAL MATCH entityRels=(e)--(e2:!Chunk) WHERE exists {\\n    (e2)<-[:HAS_ENTITY]-(other) WHERE other IN selectedChunks\\n  }\\n  RETURN collect(entities) as entities, collect(entityRels) as entityRels\\n}\\n\\nWITH apoc.coll.flatten(docs + chunks + chunkRels + entities + entityRels, true) as paths\\n\\n// distinct nodes and rels\\nCALL { WITH paths UNWIND paths AS path UNWIND nodes(path) as node WITH distinct node \\n       RETURN collect(node /* {.*, labels:labels(node), elementId:elementId(node), embedding:null, text:null} */) AS nodes }\\nCALL { WITH paths UNWIND paths AS path UNWIND relationships(path) as rel RETURN collect(distinct rel) AS rels }  \\nRETURN nodes, rels\\n\\n'\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (selectedChunks) { ... }} {position: line: 19, column: 1, offset: 630} for query: '\\nMATCH docs = (d:Document) \\nWHERE d.fileName IN $document_names\\nWITH docs, d ORDER BY d.createdAt DESC\\n// fetch chunks for documents, currently with limit\\nCALL {\\n  WITH d\\n  OPTIONAL MATCH chunks=(d)<-[:PART_OF|FIRST_CHUNK]-(c:Chunk)\\n  RETURN c, chunks LIMIT 50\\n}\\n\\nWITH collect(distinct docs) as docs, collect(distinct chunks) as chunks, collect(distinct c) as selectedChunks\\nWITH docs, chunks, selectedChunks\\n// select relationships between selected chunks\\nWITH *, \\n[ c in selectedChunks | [p=(c)-[:NEXT_CHUNK|SIMILAR]-(other) WHERE other IN selectedChunks | p]] as chunkRels\\n\\n// fetch entities and relationships between entities\\nCALL {\\n  WITH selectedChunks\\n  UNWIND selectedChunks as c\\n  \\n  OPTIONAL MATCH entities=(c:Chunk)-[:HAS_ENTITY]->(e)\\n  OPTIONAL MATCH entityRels=(e)--(e2:!Chunk) WHERE exists {\\n    (e2)<-[:HAS_ENTITY]-(other) WHERE other IN selectedChunks\\n  }\\n  RETURN collect(entities) as entities, collect(entityRels) as entityRels\\n}\\n\\nWITH apoc.coll.flatten(docs + chunks + chunkRels + entities + entityRels, true) as paths\\n\\n// distinct nodes and rels\\nCALL { WITH paths UNWIND paths AS path UNWIND nodes(path) as node WITH distinct node \\n       RETURN collect(node /* {.*, labels:labels(node), elementId:elementId(node), embedding:null, text:null} */) AS nodes }\\nCALL { WITH paths UNWIND paths AS path UNWIND relationships(path) as rel RETURN collect(distinct rel) AS rels }  \\nRETURN nodes, rels\\n\\n'\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (paths) { ... }} {position: line: 33, column: 1, offset: 1066} for query: '\\nMATCH docs = (d:Document) \\nWHERE d.fileName IN $document_names\\nWITH docs, d ORDER BY d.createdAt DESC\\n// fetch chunks for documents, currently with limit\\nCALL {\\n  WITH d\\n  OPTIONAL MATCH chunks=(d)<-[:PART_OF|FIRST_CHUNK]-(c:Chunk)\\n  RETURN c, chunks LIMIT 50\\n}\\n\\nWITH collect(distinct docs) as docs, collect(distinct chunks) as chunks, collect(distinct c) as selectedChunks\\nWITH docs, chunks, selectedChunks\\n// select relationships between selected chunks\\nWITH *, \\n[ c in selectedChunks | [p=(c)-[:NEXT_CHUNK|SIMILAR]-(other) WHERE other IN selectedChunks | p]] as chunkRels\\n\\n// fetch entities and relationships between entities\\nCALL {\\n  WITH selectedChunks\\n  UNWIND selectedChunks as c\\n  \\n  OPTIONAL MATCH entities=(c:Chunk)-[:HAS_ENTITY]->(e)\\n  OPTIONAL MATCH entityRels=(e)--(e2:!Chunk) WHERE exists {\\n    (e2)<-[:HAS_ENTITY]-(other) WHERE other IN selectedChunks\\n  }\\n  RETURN collect(entities) as entities, collect(entityRels) as entityRels\\n}\\n\\nWITH apoc.coll.flatten(docs + chunks + chunkRels + entities + entityRels, true) as paths\\n\\n// distinct nodes and rels\\nCALL { WITH paths UNWIND paths AS path UNWIND nodes(path) as node WITH distinct node \\n       RETURN collect(node /* {.*, labels:labels(node), elementId:elementId(node), embedding:null, text:null} */) AS nodes }\\nCALL { WITH paths UNWIND paths AS path UNWIND relationships(path) as rel RETURN collect(distinct rel) AS rels }  \\nRETURN nodes, rels\\n\\n'\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (paths) { ... }} {position: line: 35, column: 1, offset: 1277} for query: '\\nMATCH docs = (d:Document) \\nWHERE d.fileName IN $document_names\\nWITH docs, d ORDER BY d.createdAt DESC\\n// fetch chunks for documents, currently with limit\\nCALL {\\n  WITH d\\n  OPTIONAL MATCH chunks=(d)<-[:PART_OF|FIRST_CHUNK]-(c:Chunk)\\n  RETURN c, chunks LIMIT 50\\n}\\n\\nWITH collect(distinct docs) as docs, collect(distinct chunks) as chunks, collect(distinct c) as selectedChunks\\nWITH docs, chunks, selectedChunks\\n// select relationships between selected chunks\\nWITH *, \\n[ c in selectedChunks | [p=(c)-[:NEXT_CHUNK|SIMILAR]-(other) WHERE other IN selectedChunks | p]] as chunkRels\\n\\n// fetch entities and relationships between entities\\nCALL {\\n  WITH selectedChunks\\n  UNWIND selectedChunks as c\\n  \\n  OPTIONAL MATCH entities=(c:Chunk)-[:HAS_ENTITY]->(e)\\n  OPTIONAL MATCH entityRels=(e)--(e2:!Chunk) WHERE exists {\\n    (e2)<-[:HAS_ENTITY]-(other) WHERE other IN selectedChunks\\n  }\\n  RETURN collect(entities) as entities, collect(entityRels) as entityRels\\n}\\n\\nWITH apoc.coll.flatten(docs + chunks + chunkRels + entities + entityRels, true) as paths\\n\\n// distinct nodes and rels\\nCALL { WITH paths UNWIND paths AS path UNWIND nodes(path) as node WITH distinct node \\n       RETURN collect(node /* {.*, labels:labels(node), elementId:elementId(node), embedding:null, text:null} */) AS nodes }\\nCALL { WITH paths UNWIND paths AS path UNWIND relationships(path) as rel RETURN collect(distinct rel) AS rels }  \\nRETURN nodes, rels\\n\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of nodes : 727\n",
      "no of relations : 3084\n"
     ]
    }
   ],
   "source": [
    "# /graph_query >> get_graph_results function\n",
    "from src.graph_query import get_graphDB_driver, execute_query,extract_node_elements,extract_relationships\n",
    "from src.shared.constants import GRAPH_QUERY, GRAPH_CHUNK_LIMIT\n",
    "\n",
    "driver = get_graphDB_driver(uri,userName,password)\n",
    "query = GRAPH_QUERY.format(graph_chunk_limit=GRAPH_CHUNK_LIMIT)\n",
    "# List documents filenames into document_names. NOTE: By default method should work while empty but does not for some unknown reason. \n",
    "document_names =[\"The Central Nervous System _ Anatomy and Physiology I.pdf\",\"The Embryologic Perspective _ Anatomy and Physiology I.pdf\",\"Circulation and the Central Nervous System _ Anatomy and Physiology I.pdf\",\"The Peripheral Nervous System _ Anatomy and Physiology I.pdf\",\"Glossary_ The Nervous System _ Anatomy and Physiology I.pdf\",\"Introduction to the Nervous System _ Anatomy and Physiology I.pdf\"]\n",
    "records, summary, keys = execute_query(driver, query, document_names, doc_limit=None)\n",
    "document_nodes = extract_node_elements(records)\n",
    "document_relationships = extract_relationships(records)\n",
    "\n",
    "# print(f\"records: {records}\")\n",
    "# print(f\"summary: {summary}\")\n",
    "# print(f\"keys: {keys}\")\n",
    "\n",
    "print(f\"no of nodes : {len(document_nodes)}\")\n",
    "print(f\"no of relations : {len(document_relationships)}\")\n",
    "# results = {\n",
    "#     \"nodes\": document_nodes,\n",
    "#     \"relationships\": document_relationships\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Query the Existing Knowledge Graph**\n",
    "The Neo4j Cypher query ``` MATCH (d:Document) Return d``` shows all nodes labeled as \"Document\".\n",
    "Within the records, look for the number of chunks.\n",
    "\n",
    "**Example**\n",
    "```\n",
    "records: [<Record d=<Node element_id='4:187c0626-2398-4709-a30d-c929bee00f7d:2' \n",
    "labels=frozenset({'Document'}) \n",
    "properties={\n",
    "    'fileName': 'Anatomy_and_Physiology_CH13.pdf', \n",
    "    'errorMessage': '', \n",
    "    'fileSource': 'local file', \n",
    "    'total_chunks': 188, \n",
    "    'processingTime': 435.63, \n",
    "    'createdAt': neo4j.time.DateTime(2024, 10, 13, 23, 10, 11, 139430000), \n",
    "    'fileSize': 13380426, 'nodeCount': 799, \n",
    "    'model': 'openai-gpt-4o', \n",
    "    'processed_chunk': 188, \n",
    "    'fileType': 'pdf', \n",
    "    'relationshipCount': 532, \n",
    "    'is_cancelled': False, \n",
    "    'status': 'Completed', \n",
    "    'updatedAt': neo4j.time.DateTime(2024, 10, 13, 23, 17, 39, 134987000)}>>]```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records: [<Record d=<Node element_id='4:187c0626-2398-4709-a30d-c929bee00f7d:0' labels=frozenset({'Document'}) properties={'fileName': 'Glossary_ The Nervous System _ Anatomy and Physiology I.pdf', 'errorMessage': '', 'fileSource': 'local file', 'total_chunks': 35, 'processingTime': 141.66, 'createdAt': neo4j.time.DateTime(2024, 10, 22, 18, 57, 18, 300405000), 'fileSize': 384987, 'nodeCount': 174, 'model': 'openai-gpt-4o', 'processed_chunk': 35, 'fileType': 'pdf', 'relationshipCount': 0, 'is_cancelled': False, 'status': 'Completed', 'updatedAt': neo4j.time.DateTime(2024, 10, 22, 18, 59, 51, 989990000)}>>, <Record d=<Node element_id='4:187c0626-2398-4709-a30d-c929bee00f7d:1' labels=frozenset({'Document'}) properties={'fileName': 'The Embryologic Perspective _ Anatomy and Physiology I.pdf', 'errorMessage': '', 'fileSource': 'local file', 'total_chunks': 30, 'processingTime': 134.16, 'createdAt': neo4j.time.DateTime(2024, 10, 22, 18, 57, 18, 909662000), 'fileSize': 783572, 'nodeCount': 85, 'model': 'openai-gpt-4o', 'processed_chunk': 30, 'fileType': 'pdf', 'relationshipCount': 68, 'is_cancelled': False, 'status': 'Completed', 'updatedAt': neo4j.time.DateTime(2024, 10, 22, 19, 4, 13, 1228000)}>>, <Record d=<Node element_id='4:187c0626-2398-4709-a30d-c929bee00f7d:875' labels=frozenset({'Document'}) properties={'fileName': 'Introduction to the Nervous System _ Anatomy and Physiology I.pdf', 'errorMessage': '', 'fileSource': 'local file', 'total_chunks': 4, 'processingTime': 8.56, 'createdAt': neo4j.time.DateTime(2024, 10, 22, 18, 57, 19, 685384000), 'fileSize': 995155, 'nodeCount': 7, 'model': 'openai-gpt-4o', 'processed_chunk': 4, 'fileType': 'pdf', 'relationshipCount': 5, 'is_cancelled': False, 'status': 'Completed', 'updatedAt': neo4j.time.DateTime(2024, 10, 22, 18, 57, 38, 791211000)}>>, <Record d=<Node element_id='4:187c0626-2398-4709-a30d-c929bee00f7d:876' labels=frozenset({'Document'}) properties={'fileName': 'The Peripheral Nervous System _ Anatomy and Physiology I.pdf', 'errorMessage': '', 'fileSource': 'local file', 'total_chunks': 38, 'processingTime': 113.42, 'createdAt': neo4j.time.DateTime(2024, 10, 22, 18, 57, 20, 784773000), 'fileSize': 1733620, 'nodeCount': 99, 'model': 'openai-gpt-4o', 'processed_chunk': 38, 'fileType': 'pdf', 'relationshipCount': 56, 'is_cancelled': False, 'status': 'Completed', 'updatedAt': neo4j.time.DateTime(2024, 10, 22, 19, 1, 46, 683244000)}>>, <Record d=<Node element_id='4:187c0626-2398-4709-a30d-c929bee00f7d:878' labels=frozenset({'Document'}) properties={'fileName': 'Circulation and the Central Nervous System _ Anatomy and Physiology I.pdf', 'errorMessage': '', 'fileSource': 'local file', 'total_chunks': 36, 'processingTime': 125.01, 'createdAt': neo4j.time.DateTime(2024, 10, 22, 18, 57, 21, 175603000), 'fileSize': 1835108, 'nodeCount': 90, 'model': 'openai-gpt-4o', 'processed_chunk': 36, 'fileType': 'pdf', 'relationshipCount': 69, 'is_cancelled': False, 'status': 'Completed', 'updatedAt': neo4j.time.DateTime(2024, 10, 22, 19, 1, 58, 22980000)}>>, <Record d=<Node element_id='4:187c0626-2398-4709-a30d-c929bee00f7d:1646' labels=frozenset({'Document'}) properties={'fileName': 'The Central Nervous System _ Anatomy and Physiology I.pdf', 'errorMessage': '', 'fileSource': 'local file', 'total_chunks': 57, 'processingTime': 166.33, 'createdAt': neo4j.time.DateTime(2024, 10, 22, 19, 41, 51, 530119000), 'fileSize': 2193405, 'nodeCount': 144, 'model': 'openai-gpt-4o', 'processed_chunk': 57, 'fileType': 'pdf', 'relationshipCount': 129, 'is_cancelled': False, 'status': 'Completed', 'updatedAt': neo4j.time.DateTime(2024, 10, 22, 19, 44, 42, 980172000)}>>]\n"
     ]
    }
   ],
   "source": [
    "# /graph_query >> Query test\n",
    "from src.graph_query import get_graphDB_driver, execute_query,extract_node_elements,extract_relationships\n",
    "\n",
    "driver = get_graphDB_driver(uri,userName,password)\n",
    "query =  \"\"\"\n",
    "MATCH (d:Document)\n",
    "RETURN d\n",
    "\n",
    "\"\"\"  # labels are case-sensitive\n",
    "records, summary, keys = execute_query(driver, query, document_names, doc_limit=None)\n",
    "document_nodes = extract_node_elements(records)\n",
    "document_relationships = extract_relationships(records)\n",
    "\n",
    "print(f\"records: {records}\")\n",
    "# print(f\"summary: {summary}\")\n",
    "# print(f\"keys: {keys}\")\n",
    "# print(f\"document_nodes: {document_nodes}\")\n",
    "# print(f\"document_relationships: {document_relationships}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Retrieval**\n",
    "Given a Neo4j graph-vector store database, the performance of document retrieval is determined the quality of translation of the initial user query and execution of the cypher query with the Neo4j database.  Traditional data science metrics (i.e precision, recall, F1 score) are used to measure the amount of relevant documents the GraphQARetriever can obtain. Different modes of retrieval (i.e graph-only, vector-only, hybrid (vector and keyword) search, and hybrid-cypher-query search were explored within this Juypter Notebook.\n",
    "\n",
    "**Levers of Control**\n",
    "- **Query to Cypher Statement**\n",
    "  - Converting the user query to relevant cypher statement using llm (i.e Gemini, OpenAI) prior to creating a document retriever object.\n",
    "- **Query to Embedding**\n",
    "  - Converting the user query to text embedding for vector similarity search (default cosine similarity)\n",
    "- **Document Retrieval Assessment**\n",
    "  - Retrieving the relevant documents from the Graph/Vector DB (i.e GraphQARetriever) using various graph traversal and vector similarity serach techniques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shinhojung/llm-graph-builder/backend/src/shared/common_fn.py:89: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embeddings = SentenceTransformerEmbeddings(\n",
      "/home/shinhojung/llm-graph-builder/backend/.venv/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is graph response:\n",
      "{'response': \"I don't know the answer. \\n\", 'cypher_query': 'MATCH (a:Anatomical_structure {description: \"Circle of Willis\"})<-[:PART_OF]-(b:Anatomical_structure) WHERE b.description CONTAINS \"artery\" RETURN b.description', 'context': []}\n"
     ]
    }
   ],
   "source": [
    "# Deconstructed: /chat_bot API >> QA_RAG >> create_graph_chain\n",
    "from src.llm import get_llm\n",
    "import langchain_community.graphs.neo4j_graph as n\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "\n",
    "# Fetching graph from database using user agent\n",
    "graph = n.Neo4jGraph(url=uri,username=userName,password=password,database=database,sanitize = True, refresh_schema=True, driver_config={'user_agent':os.environ.get('NEO4J_USER_AGENT')})\n",
    "\n",
    "# RAG Parameters\n",
    "model=\"gemini-1.5-flash-001\"\n",
    "question=\"What are all the arteries in the Circle of Willis\"\n",
    "session_id = None\n",
    "\n",
    "# Create graph chain\n",
    "cypher_llm,model_name = get_llm(model)\n",
    "qa_llm,model_name = get_llm(model)\n",
    "graph_chain = GraphCypherQAChain.from_llm(\n",
    "    cypher_llm=cypher_llm,\n",
    "    qa_llm=qa_llm,\n",
    "    validate_cypher= True,\n",
    "    graph=graph,\n",
    "    # verbose=True, \n",
    "    return_intermediate_steps = True,\n",
    "    top_k=3\n",
    ")\n",
    "\n",
    "# print(graph_chain)\n",
    "# print(qa_llm)\n",
    "\n",
    "# Deconstructed: /chat_bot API >> QA_RAG >> get_graph_response\n",
    "# Graph Retrieval\n",
    "from src.QA_integration_new import get_graph_response\n",
    "graph_response = get_graph_response(graph_chain,question)\n",
    "print(\"This is graph response:\")\n",
    "print(graph_response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Response**\n",
    "After retrieving the relevant documents, the llm-graph-builder aggregations the chunks in sequential order while filtering out less relevant infromation. Then, the query response summarized\n",
    "\n",
    "**Levers of Control**\n",
    "- **Embedding to Response**\n",
    "  - Converting the embedding of the retrieved documents to human readable response (using LLM i.e Gemini)\n",
    "- **Human and Validation Assessment**\n",
    "  - Ensuring if the response answers the original query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ") model_name='all-MiniLM-L6-v2' cache_folder=None model_kwargs={} encode_kwargs={} multi_process=False show_progress=False\n"
     ]
    }
   ],
   "source": [
    "from src.QA_integration_new import load_embedding_model\n",
    "# Identify the embedding model\n",
    "EMBEDDING_MODEL = os.getenv('EMBEDDING_MODEL')\n",
    "EMBEDDING_FUNCTION , _ = load_embedding_model(EMBEDDING_MODEL)\n",
    "# Identify the LLM used\n",
    "llm,model_name = get_llm(model)\n",
    "\n",
    "print(EMBEDDING_FUNCTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='What are all the arteries in the Circle of Willis')]\n"
     ]
    }
   ],
   "source": [
    "# Create messages needed to prompt LLM to retreive human readable response text\n",
    "from src.QA_integration_new import create_neo4j_chat_message_history\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "history = create_neo4j_chat_message_history(graph, session_id=\" \")\n",
    "messages = history.messages\n",
    "user_question = HumanMessage(content=question)\n",
    "messages.append(user_question)\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Vector Search**\n",
    "\n",
    "- Performs primarily based on vector similarity between query embedding and embedding property of nodes within the knowledge graph.\n",
    "- Though primarily utilizes vector index search, the ```VECTOR_SEARCH_QUERY``` also focuses soley on ```PART_OF``` relationships, where a chunk is a part of document, ignoring any other relationships or entitites in the graph.\n",
    "- Does not perform any other specific entity-based matching or similarity checks (more suitable for more starightforward document retrieval based soley on chunk scores)\n",
    "\n",
    "#### **Scoring**\n",
    "- The embedding of each chunk node (i.e a text segment) is evaluated for similarity with the input query embedding.\n",
    "- For each document, the scores of all chunks are averaged via 'avg(score)' to generate a single socre representing the document. This average score gives an overall measure of how relevant the coument is to the query.\n",
    "- **Return Value**: This average score is returned as the score for each document, alongside the concatenated text from its chunks and relevant metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "message: The Circle of Willis is a ring-shaped structure at the base of the brain that ensures continuous blood flow to the brain. It is formed by the following arteries:\n",
      "\n",
      "* **Internal carotid arteries:** These arteries branch from the common carotid arteries and enter the skull through the carotid canal.\n",
      "* **Anterior cerebral arteries:** These arteries arise from the internal carotid arteries and supply blood to the frontal lobes and parts of the parietal lobes.\n",
      "* **Anterior communicating artery:** This small artery connects the two anterior cerebral arteries.\n",
      "* **Posterior cerebral arteries:** These arteries arise from the basilar artery and supply blood to the occipital lobes and parts of the temporal lobes.\n",
      "* **Posterior communicating arteries:** These arteries connect the internal carotid arteries to the posterior cerebral arteries.\n",
      "* **Basilar artery:** This artery is formed by the merger of the two vertebral arteries and supplies blood to the brainstem and cerebellum. \n",
      "\n",
      "sources: {'Circulation and the Central Nervous System _ Anatomy and Physiology I.pdf', 'Glossary_ The Nervous System _ Anatomy and Physiology I.pdf'}\n",
      "chunkdetails: [{'id': 'df99f8192bf2961d93f8fa02eb32337088dbeffb', 'score': 0.8399}, {'id': 'f73ae203cb7d3238826460d93b4dcbef24801c62', 'score': 0.8053}, {'id': '8eee3b357209bc21f61d633156b9d00b829ddc73', 'score': 0.7228}, {'id': '24564789b83b665072530bcf37943ede49aa1201', 'score': 0.7243}]\n",
      "total_tokens: 1481\n",
      "mode: vector\n"
     ]
    }
   ],
   "source": [
    "# Deconstructed: /chat_bot API >> QA_RAG >> VECTOR_GRAPH_SEARCH and setup_chat\n",
    "# Different from RAG_Graph\n",
    "from src.shared.constants import VECTOR_SEARCH_QUERY\n",
    "from src.QA_integration_new import retrieve_documents, process_documents, create_document_retriever_chain\n",
    "from src.shared.constants import CHAT_SEARCH_KWARG_K, CHAT_SEARCH_KWARG_SCORE_THRESHOLD\n",
    "from src.QA_integration_new import format_documents, get_rag_chain, get_sources_and_chunks, get_total_tokens\n",
    "from langchain_community.vectorstores.neo4j_vector import Neo4jVector\n",
    "\n",
    "def vector_retrieval():\n",
    "    mode = \"vector\"\n",
    "\n",
    "    # under QA_RAG with Hybrid Search\n",
    "    retrieval_query = VECTOR_SEARCH_QUERY\n",
    "\n",
    "    # Create retriever\n",
    "    index_name = \"vector\"  # default\n",
    "    score_threshold=CHAT_SEARCH_KWARG_SCORE_THRESHOLD\n",
    "\n",
    "    # Vectors within a graph (aka. setup chat)\n",
    "    neo_db = Neo4jVector.from_existing_index(\n",
    "                    embedding=EMBEDDING_FUNCTION,\n",
    "                    index_name=index_name,\n",
    "                    retrieval_query=retrieval_query,\n",
    "                    graph=graph\n",
    "                )\n",
    "    retriever = neo_db.as_retriever(search_type=\"similarity_score_threshold\",search_kwargs={\"score_threshold\": score_threshold}) # default k = 4 not 3\n",
    "    doc_retriever = create_document_retriever_chain(llm, retriever)\n",
    "    return doc_retriever, mode\n",
    "\n",
    "doc_retriever, mode = vector_retrieval()\n",
    "docs = retrieve_documents(doc_retriever, messages)\n",
    "\n",
    "if docs:\n",
    "    formatted_docs, sources = format_documents(docs,model)\n",
    "    rag_chain = get_rag_chain(llm=llm)\n",
    "    ai_response = rag_chain.invoke({\n",
    "        \"messages\": messages,\n",
    "        \"context\": formatted_docs,\n",
    "        \"input\": question \n",
    "    })\n",
    "    result = get_sources_and_chunks(sources, docs)\n",
    "    content = ai_response.content\n",
    "    total_tokens = get_total_tokens(ai_response,llm)\n",
    "else:\n",
    "    content = \"I couldn't find any relevant documents to answer your question.\"\n",
    "    result = {\"sources\": [], \"chunkdetails\": []}\n",
    "    total_tokens = 0\n",
    "\n",
    "vector_content = content\n",
    "vector_result = result\n",
    "vector_total_tokens = total_tokens\n",
    "print()\n",
    "print(f\"message: {vector_content}\")\n",
    "print(f\"sources: {vector_result['sources']}\")\n",
    "# print(f\"model: {model_version}\")\n",
    "print(f\"chunkdetails: {vector_result['chunkdetails']}\")\n",
    "print(f\"total_tokens: {vector_total_tokens}\")\n",
    "print(f\"mode: {mode}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hybrid (Vector+Keyword) Search**\n",
    "- Utilizes both vector and full-text index to query relevant documents.\n",
    "- Incorporates ```HAS_ENTITY``` relationships and allows the query to handle both embedded entities and multiple levels of relationships\n",
    "- Uses cosine similarity checks between chunk embeddings and entity embeddings to filter entities based on configurable similarity thresholds (embedding_match_min and embedding_match_max)\n",
    "- Allows for recurisve querying to a configurable depth, capturing paths to connected entities and allowing the search to pull in more contextually relevant nodes\n",
    "- Suitable for applications that require an understanding of semantic connections between entities within a graph, such as knowledge graph exploartion, entity-based search, or contextual entity disambiguation\n",
    "\n",
    "#### **Scoring**\n",
    "- **Score Collection and Averaging**: Similar to ```VECTOR_SEARCH_QUERY```, each chunk has an initial score, and for each document, the scores of chunks are averaged to produce ```avg_score```\n",
    "- **Entity Filtering with Embeddings**: Entities connected to each ```chunk``` are included based on embedding similarity threshold, using cosine similarity.\n",
    "  - Enitties without embeddings are directly included\n",
    "  - Entities with embeddings are included if their cosine similarity to the query embedding falls within the specified range (```embedding_match_min``` and ```embedding_match_max```).\n",
    "  - If an entity's similarity exceeds the ```embedding_match_max```, broader relationships are included in the entity's graph.\n",
    "- **Return Value**: Like ```VECTOR_SEARCH_QUERY```, the ```avg_score``` is returned as the main score; however, this score now incorporates a more complex structure of entities and relationships relevant to the query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: 'CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 740} for query: 'CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "message: The Circle of Willis is a network of arteries at the base of the brain. The arteries that contribute to the Circle of Willis are:\n",
      "\n",
      "* **Internal carotid arteries:** These arteries enter the cranium through the carotid canal and branch into the anterior cerebral artery and the middle cerebral artery.\n",
      "* **Vertebral arteries:** These arteries merge to form the basilar artery, which then branches into the posterior cerebral arteries. \n",
      "\n",
      "The Circle of Willis is crucial for maintaining blood flow to the brain, even if there is a blockage in one of the arteries. \n",
      "\n",
      "sources: {'Circulation and the Central Nervous System _ Anatomy and Physiology I.pdf', 'Glossary_ The Nervous System _ Anatomy and Physiology I.pdf'}\n",
      "chunkdetails: [{'id': 'df99f8192bf2961d93f8fa02eb32337088dbeffb', 'score': 1.0}, {'id': 'f73ae203cb7d3238826460d93b4dcbef24801c62', 'score': 0.9588}, {'id': '8eee3b357209bc21f61d633156b9d00b829ddc73', 'score': 0.8606}, {'id': '24564789b83b665072530bcf37943ede49aa1201', 'score': 0.8623}]\n",
      "total_tokens: 2792\n",
      "mode: graph + vector + fulltext\n",
      "predict_time: 0.9027941226959229\n"
     ]
    }
   ],
   "source": [
    "# Deconstructed: /chat_bot API >> QA_RAG >> VECTOR_GRAPH_SEARCH and setup_chat\n",
    "# Different from RAG_Graph\n",
    "from src.shared.constants import VECTOR_GRAPH_SEARCH_QUERY, VECTOR_GRAPH_SEARCH_ENTITY_LIMIT, VECTOR_SEARCH_QUERY\n",
    "from src.QA_integration_new import retrieve_documents, process_documents, create_document_retriever_chain\n",
    "from src.shared.constants import CHAT_SEARCH_KWARG_K, CHAT_SEARCH_KWARG_SCORE_THRESHOLD\n",
    "from langchain_community.vectorstores.neo4j_vector import Neo4jVector\n",
    "\n",
    "\n",
    "def hybrid_retrieval():\n",
    "    mode =\"graph + vector + fulltext\"\n",
    "\n",
    "    # under QA_RAG with Hybrid Search\n",
    "    retrieval_query = VECTOR_GRAPH_SEARCH_QUERY.format(no_of_entites=VECTOR_GRAPH_SEARCH_ENTITY_LIMIT)\n",
    "\n",
    "    # Create retriever\n",
    "    index_name = \"vector\"\n",
    "    keyword_index = \"keyword\"\n",
    "    search_k=CHAT_SEARCH_KWARG_K, \n",
    "    score_threshold=CHAT_SEARCH_KWARG_SCORE_THRESHOLD\n",
    "\n",
    "    # Vectors within a graph (aka. setup chat)\n",
    "    neo_db = Neo4jVector.from_existing_graph(\n",
    "                    embedding=EMBEDDING_FUNCTION,\n",
    "                    index_name=index_name,\n",
    "                    retrieval_query=retrieval_query,\n",
    "                    graph=graph,\n",
    "                    search_type=\"hybrid\",\n",
    "                    node_label=\"Chunk\",\n",
    "                    embedding_node_property=\"embedding\",\n",
    "                    text_node_properties=[\"text\"],\n",
    "                    keyword_index_name=keyword_index\n",
    "                    )\n",
    "    retriever = neo_db.as_retriever(search_type=\"similarity_score_threshold\",search_kwargs={\"score_threshold\": score_threshold}) # default k = 4 not 3\n",
    "    doc_retriever = create_document_retriever_chain(llm, retriever)\n",
    "    return doc_retriever, mode\n",
    "\n",
    "# Initiate the retrieval\n",
    "doc_retriever, mode = hybrid_retrieval()\n",
    "docs = retrieve_documents(doc_retriever, messages)\n",
    "\n",
    "if docs:\n",
    "    content, result, total_tokens, predict_time = process_documents(docs, question, messages, llm,model)\n",
    "else:\n",
    "    content = \"I couldn't find any relevant documents to answer your question.\"\n",
    "    result = {\"sources\": [], \"chunkdetails\": []}\n",
    "    total_tokens = 0\n",
    "\n",
    "\n",
    "hybrid_content = content\n",
    "hybrid_result = result\n",
    "hybrid_total_tokens = total_tokens\n",
    "\n",
    "print()\n",
    "print(f\"message: {hybrid_content}\")\n",
    "print(f\"sources: {hybrid_result['sources']}\")\n",
    "# print(f\"model: {model_version}\")\n",
    "print(f\"chunkdetails: {hybrid_result['chunkdetails']}\")\n",
    "print(f\"total_tokens: {hybrid_total_tokens}\")\n",
    "print(f\"mode: {mode}\")\n",
    "print(f\"predict_time: {predict_time}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hybrid Cypher Retriever**\n",
    "- Conducts another cypher search on top of hybrid (vector+keyword) search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 849} for query: 'CALL () { CALL db.index.vector.queryNodes($vector_index_name, $top_k, $query_vector) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS vector_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / vector_index_max_score) AS score UNION CALL db.index.fulltext.queryNodes($fulltext_index_name, $query_text, {limit: $top_k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS ft_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / ft_index_max_score) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $top_k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 849} for query: 'CALL () { CALL db.index.vector.queryNodes($vector_index_name, $top_k, $query_vector) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS vector_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / vector_index_max_score) AS score UNION CALL db.index.fulltext.queryNodes($fulltext_index_name, $query_text, {limit: $top_k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS ft_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / ft_index_max_score) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $top_k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The arteries that contribute to the Circle of Willis are:\n",
      "\n",
      "* **Internal Carotid Arteries** \n",
      "* **Vertebral Arteries** \n",
      "* **Basilar Artery** \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Deconstructed: /chat_bot API >> QA_RAG >> VECTOR_GRAPH_SEARCH and setup_chat\n",
    "# Different from RAG_Graph\n",
    "from src.shared.constants import VECTOR_GRAPH_SEARCH_QUERY, VECTOR_GRAPH_SEARCH_ENTITY_LIMIT, VECTOR_SEARCH_QUERY\n",
    "from src.QA_integration_new import retrieve_documents, process_documents, create_document_retriever_chain\n",
    "from src.shared.constants import CHAT_SEARCH_KWARG_K, CHAT_SEARCH_KWARG_SCORE_THRESHOLD\n",
    "from src.llm import get_llm\n",
    "from neo4j_graphrag.retrievers import HybridCypherRetriever\n",
    "from neo4j_graphrag.generation import GraphRAG\n",
    "from neo4j_graphrag.llm import VertexAILLM\n",
    "\n",
    "mode =\"graph + vector + fulltext\"\n",
    "\n",
    "# under QA_RAG with Hybrid Search\n",
    "retrieval_query = VECTOR_GRAPH_SEARCH_QUERY.format(no_of_entites=VECTOR_GRAPH_SEARCH_ENTITY_LIMIT)\n",
    "\n",
    "# Create retriever\n",
    "index_name = \"vector\"\n",
    "keyword_index = \"keyword\"\n",
    "\n",
    "retriever = HybridCypherRetriever(\n",
    "    driver=driver,\n",
    "    vector_index_name=index_name,\n",
    "    fulltext_index_name=keyword_index,\n",
    "    retrieval_query=retrieval_query,\n",
    "    embedder=EMBEDDING_FUNCTION,\n",
    ")\n",
    "\n",
    "llm = VertexAILLM(model_name=\"gemini-1.5-flash-001\")\n",
    "rag = GraphRAG(retriever=retriever, llm=llm)\n",
    "\n",
    "retriever_result = retriever.search(query_text=question, top_k=4)\n",
    "hybridcypher_response = rag.search(query_text=question,retriever_config={\"top_k\":4})\n",
    "print()\n",
    "print(hybridcypher_response.answer)\n",
    "print()\n",
    "hybridcypher_chunkdetails = []\n",
    "for m in retriever_result.items:\n",
    "    hybridcypher_chunkdetails.append(m.metadata[\"chunkdetails\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Compare Graph, Vector, Hybrid (Vector+Keyword), vs. Hybrid Cypher Retrieval**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to extract ref text\n",
    "def getChunkDetails(chunkdetails: list):\n",
    "    chunkdetails = sorted(chunkdetails, key=lambda x:x[\"score\"], reverse=True)\n",
    "    driver = GraphDatabase.driver(\n",
    "        uri = uri,\n",
    "        auth = (os.environ[\"NEO4J_USERNAME\"], os.environ[\"NEO4J_PASSWORD\"])\n",
    "    )\n",
    "    session = driver.session()\n",
    "    \n",
    "    list_text = []\n",
    "    \n",
    "    for chunk in chunkdetails:\n",
    "        id = chunk[\"id\"]\n",
    "        score = chunk[\"score\"]\n",
    "        cypher = \"MATCH (n:Chunk) WHERE n.id = $id Return n\"    \n",
    "        data = session.run(cypher,id=id).data()\n",
    "        text = data[0][\"n\"][\"text\"]\n",
    "        fileName = data[0][\"n\"][\"fileName\"]\n",
    "        list_text.append((fileName,text,score,id))\n",
    "    return list_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************\n",
      "This is Graph-only response \n",
      "\n",
      "I don't know the answer. \n",
      "\n",
      "************************************************\n",
      "This is Vector-only response s\n",
      "\n",
      "The Circle of Willis is a ring-shaped structure at the base of the brain that ensures continuous blood flow to the brain. It is formed by the following arteries:\n",
      "\n",
      "* **Internal carotid arteries:** These arteries branch from the common carotid arteries and enter the skull through the carotid canal.\n",
      "* **Anterior cerebral arteries:** These arteries arise from the internal carotid arteries and supply blood to the frontal lobes and parts of the parietal lobes.\n",
      "* **Anterior communicating artery:** This small artery connects the two anterior cerebral arteries.\n",
      "* **Posterior cerebral arteries:** These arteries arise from the basilar artery and supply blood to the occipital lobes and parts of the temporal lobes.\n",
      "* **Posterior communicating arteries:** These arteries connect the internal carotid arteries to the posterior cerebral arteries.\n",
      "* **Basilar artery:** This artery is formed by the merger of the two vertebral arteries and supplies blood to the brainstem and cerebellum. \n",
      "\n",
      "Document Retrieval Scores:\n",
      "[{'id': 'df99f8192bf2961d93f8fa02eb32337088dbeffb', 'score': 0.8399}, {'id': 'f73ae203cb7d3238826460d93b4dcbef24801c62', 'score': 0.8053}, {'id': '8eee3b357209bc21f61d633156b9d00b829ddc73', 'score': 0.7228}, {'id': '24564789b83b665072530bcf37943ede49aa1201', 'score': 0.7243}]\n",
      "\n",
      "************************************************\n",
      "This is Hybrid (Vector + Keyword Search) response \t processing time: 0.903 s\n",
      "\n",
      "The Circle of Willis is a network of arteries at the base of the brain. The arteries that contribute to the Circle of Willis are:\n",
      "\n",
      "* **Internal carotid arteries:** These arteries enter the cranium through the carotid canal and branch into the anterior cerebral artery and the middle cerebral artery.\n",
      "* **Vertebral arteries:** These arteries merge to form the basilar artery, which then branches into the posterior cerebral arteries. \n",
      "\n",
      "The Circle of Willis is crucial for maintaining blood flow to the brain, even if there is a blockage in one of the arteries. \n",
      "\n",
      "Document Retrieval Scores:\n",
      "[{'id': 'df99f8192bf2961d93f8fa02eb32337088dbeffb', 'score': 1.0}, {'id': 'f73ae203cb7d3238826460d93b4dcbef24801c62', 'score': 0.9588}, {'id': '8eee3b357209bc21f61d633156b9d00b829ddc73', 'score': 0.8606}, {'id': '24564789b83b665072530bcf37943ede49aa1201', 'score': 0.8623}]\n",
      "************************************************\n",
      "This is HybridCypherRetriever Response \n",
      "\n",
      "The arteries that contribute to the Circle of Willis are:\n",
      "\n",
      "* **Internal Carotid Arteries** \n",
      "* **Vertebral Arteries** \n",
      "* **Basilar Artery** \n",
      "\n",
      "Document Retrieval Scores:\n",
      "[{'id': 'df99f8192bf2961d93f8fa02eb32337088dbeffb', 'score': 1.0}, {'id': 'f73ae203cb7d3238826460d93b4dcbef24801c62', 'score': 0.9588419857107536}, {'id': '8eee3b357209bc21f61d633156b9d00b829ddc73', 'score': 0.8605653077717683}]\n",
      "************************************************\n",
      "************************************************\n",
      "Circulation and the Central Nervous System _ Anatomy and Physiology I.pdf \t score:0.8399\n",
      "of the basilar artery all become the circle of Willis, a confluence of arter‐ ies that can maintain perfusion of the brain even if narrowing or a block‐ age limits flow through one part (Figure 1). Watch this animation to see how blood flows to the brain and passes through the circle of Willis before being distributed through the cerebrum. The circle of Willis is a specialized arrange‐ ment of arteries that ensure constant perfusion of the cerebrum even in the event of a blockage of one of the arteries in the circle. The animation shows the normal direction of flow through the cir‐ cle of Willis to the middle cerebral artery. Where would the blood come from if there were a blockage just posterior to the middle cerebral artery on the left? Venous Return After passing through the CNS, blood returns to the circulation through a series of dural sinuses and veins (Figure 2). The superior sagittal si‐ n \n",
      "\n",
      "Circulation and the Central Nervous System _ Anatomy and Physiology I.pdf \t score:0.8053\n",
      "Figure 1. Circle of Willis. The blood supply to the brain enters through the internal carotid arteries and the vertebral arteries, eventually giving rise to the circle of Willis. Arterial Supply The major artery carrying recently oxygenated blood away from the heart is the aorta. The very first branches off the aorta supply the heart with nutrients and oxygen. The next branches give rise to the common carotid arteries, which further branch into the in‐ ternal carotid arteries. The exter‐ nal carotid arteries supply blood to the tissues on the surface of the cranium. The bases of the common carotids contain stretch receptors that immediately re‐ spond to the drop in blood pres‐ sure upon standing. The ortho‐ static reflex is a reaction to this change in body position, so that blood pressure is maintained against the increasing effect of gravity (orthostatic means “stand‐ ing up \n",
      "\n",
      "Glossary_ The Nervous System _ Anatomy and Physiology I.pdf \t score:0.7243\n",
      "choroid plexus: specialized structures containing ependymal cells lining blood capillaries that filter blood to produce CSF in the four ventricles of the brain circle of Willis: unique anatomical arrangement of blood vessels around the base of the brain that maintains perfusion of blood into the brain even if one component of the structure is blocked or narrowed common carotid artery: blood vessel that branches off the aorta (or the brachiocephalic artery on the right) and supplies blood to the head and neck corpus callosum: large white matter structure that connects the right and left cerebral hemispheres cranial nerve ganglion: sensory ganglion of cranial nerves cranial nerve: one of twelve nerves connected to the brain that are re‐ sponsible for sensory or motor functions of the head and neck descending tract: central nervous system fibers carrying motor com‐ mands from the brain to the spinal cord or periphery diencephalon: region of the \n",
      "\n",
      "Circulation and the Central Nervous System _ Anatomy and Physiology I.pdf \t score:0.7228\n",
      " pressure is maintained against the increasing effect of gravity (orthostatic means “stand‐ ing up”). Heart rate increases—a reflex of the sympathetic division of the autonomic nervous system—and this raises blood pressure. The internal carotid artery enters the cranium through the carotid canal in the temporal bone. A second set of vessels that supply the CNS are the vertebral arteries, which are protected as they pass through the neck region by the transverse foramina of the cervical vertebrae. The vertebral arteries enter the cranium through the foramen magnum of the occipital bone. Branches off the left and right vertebral arteries merge into the anterior spinal artery supplying the anterior aspect of the spinal cord, found along the anterior median fissure. The two vertebral arteries then merge into the basilar artery, which gives rise to branches to the brain stem and cerebellum. The left \n",
      "\n",
      "************************************************\n",
      "Circulation and the Central Nervous System _ Anatomy and Physiology I.pdf \t score:1.0\n",
      "of the basilar artery all become the circle of Willis, a confluence of arter‐ ies that can maintain perfusion of the brain even if narrowing or a block‐ age limits flow through one part (Figure 1). Watch this animation to see how blood flows to the brain and passes through the circle of Willis before being distributed through the cerebrum. The circle of Willis is a specialized arrange‐ ment of arteries that ensure constant perfusion of the cerebrum even in the event of a blockage of one of the arteries in the circle. The animation shows the normal direction of flow through the cir‐ cle of Willis to the middle cerebral artery. Where would the blood come from if there were a blockage just posterior to the middle cerebral artery on the left? Venous Return After passing through the CNS, blood returns to the circulation through a series of dural sinuses and veins (Figure 2). The superior sagittal si‐ n \n",
      "\n",
      "Circulation and the Central Nervous System _ Anatomy and Physiology I.pdf \t score:0.9588\n",
      "Figure 1. Circle of Willis. The blood supply to the brain enters through the internal carotid arteries and the vertebral arteries, eventually giving rise to the circle of Willis. Arterial Supply The major artery carrying recently oxygenated blood away from the heart is the aorta. The very first branches off the aorta supply the heart with nutrients and oxygen. The next branches give rise to the common carotid arteries, which further branch into the in‐ ternal carotid arteries. The exter‐ nal carotid arteries supply blood to the tissues on the surface of the cranium. The bases of the common carotids contain stretch receptors that immediately re‐ spond to the drop in blood pres‐ sure upon standing. The ortho‐ static reflex is a reaction to this change in body position, so that blood pressure is maintained against the increasing effect of gravity (orthostatic means “stand‐ ing up \n",
      "\n",
      "Glossary_ The Nervous System _ Anatomy and Physiology I.pdf \t score:0.8623\n",
      "choroid plexus: specialized structures containing ependymal cells lining blood capillaries that filter blood to produce CSF in the four ventricles of the brain circle of Willis: unique anatomical arrangement of blood vessels around the base of the brain that maintains perfusion of blood into the brain even if one component of the structure is blocked or narrowed common carotid artery: blood vessel that branches off the aorta (or the brachiocephalic artery on the right) and supplies blood to the head and neck corpus callosum: large white matter structure that connects the right and left cerebral hemispheres cranial nerve ganglion: sensory ganglion of cranial nerves cranial nerve: one of twelve nerves connected to the brain that are re‐ sponsible for sensory or motor functions of the head and neck descending tract: central nervous system fibers carrying motor com‐ mands from the brain to the spinal cord or periphery diencephalon: region of the \n",
      "\n",
      "Circulation and the Central Nervous System _ Anatomy and Physiology I.pdf \t score:0.8606\n",
      " pressure is maintained against the increasing effect of gravity (orthostatic means “stand‐ ing up”). Heart rate increases—a reflex of the sympathetic division of the autonomic nervous system—and this raises blood pressure. The internal carotid artery enters the cranium through the carotid canal in the temporal bone. A second set of vessels that supply the CNS are the vertebral arteries, which are protected as they pass through the neck region by the transverse foramina of the cervical vertebrae. The vertebral arteries enter the cranium through the foramen magnum of the occipital bone. Branches off the left and right vertebral arteries merge into the anterior spinal artery supplying the anterior aspect of the spinal cord, found along the anterior median fissure. The two vertebral arteries then merge into the basilar artery, which gives rise to branches to the brain stem and cerebellum. The left \n",
      "\n",
      "************************************************\n",
      "Circulation and the Central Nervous System _ Anatomy and Physiology I.pdf \t score:1.0\n",
      "of the basilar artery all become the circle of Willis, a confluence of arter‐ ies that can maintain perfusion of the brain even if narrowing or a block‐ age limits flow through one part (Figure 1). Watch this animation to see how blood flows to the brain and passes through the circle of Willis before being distributed through the cerebrum. The circle of Willis is a specialized arrange‐ ment of arteries that ensure constant perfusion of the cerebrum even in the event of a blockage of one of the arteries in the circle. The animation shows the normal direction of flow through the cir‐ cle of Willis to the middle cerebral artery. Where would the blood come from if there were a blockage just posterior to the middle cerebral artery on the left? Venous Return After passing through the CNS, blood returns to the circulation through a series of dural sinuses and veins (Figure 2). The superior sagittal si‐ n \n",
      "\n",
      "Circulation and the Central Nervous System _ Anatomy and Physiology I.pdf \t score:0.9588419857107536\n",
      "Figure 1. Circle of Willis. The blood supply to the brain enters through the internal carotid arteries and the vertebral arteries, eventually giving rise to the circle of Willis. Arterial Supply The major artery carrying recently oxygenated blood away from the heart is the aorta. The very first branches off the aorta supply the heart with nutrients and oxygen. The next branches give rise to the common carotid arteries, which further branch into the in‐ ternal carotid arteries. The exter‐ nal carotid arteries supply blood to the tissues on the surface of the cranium. The bases of the common carotids contain stretch receptors that immediately re‐ spond to the drop in blood pres‐ sure upon standing. The ortho‐ static reflex is a reaction to this change in body position, so that blood pressure is maintained against the increasing effect of gravity (orthostatic means “stand‐ ing up \n",
      "\n",
      "Circulation and the Central Nervous System _ Anatomy and Physiology I.pdf \t score:0.8605653077717683\n",
      " pressure is maintained against the increasing effect of gravity (orthostatic means “stand‐ ing up”). Heart rate increases—a reflex of the sympathetic division of the autonomic nervous system—and this raises blood pressure. The internal carotid artery enters the cranium through the carotid canal in the temporal bone. A second set of vessels that supply the CNS are the vertebral arteries, which are protected as they pass through the neck region by the transverse foramina of the cervical vertebrae. The vertebral arteries enter the cranium through the foramen magnum of the occipital bone. Branches off the left and right vertebral arteries merge into the anterior spinal artery supplying the anterior aspect of the spinal cord, found along the anterior median fissure. The two vertebral arteries then merge into the basilar artery, which gives rise to branches to the brain stem and cerebellum. The left \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Helper function to extract ref text\n",
    "def getChunkDetails(chunkdetails: list):\n",
    "    chunkdetails = sorted(chunkdetails, key=lambda x:x[\"score\"], reverse=True)\n",
    "    driver = GraphDatabase.driver(\n",
    "        uri = uri,\n",
    "        auth = (os.environ[\"NEO4J_USERNAME\"], os.environ[\"NEO4J_PASSWORD\"])\n",
    "    )\n",
    "    session = driver.session()\n",
    "    \n",
    "    list_text = []\n",
    "    \n",
    "    for chunk in chunkdetails:\n",
    "        id = chunk[\"id\"]\n",
    "        score = chunk[\"score\"]\n",
    "        cypher = \"MATCH (n:Chunk) WHERE n.id = $id Return n\"    \n",
    "        data = session.run(cypher,id=id).data()\n",
    "        text = data[0][\"n\"][\"text\"]\n",
    "        fileName = data[0][\"n\"][\"fileName\"]\n",
    "        list_text.append((fileName,text,score,id))\n",
    "    return list_text\n",
    "\n",
    "# Print out reponses of different retrieval methods\n",
    "print(\"************************************************\")\n",
    "print(f\"This is Graph-only response \\n\")\n",
    "print(graph_response['response'])\n",
    "\n",
    "\n",
    "print(\"************************************************\")\n",
    "print(f\"This is Vector-only response s\\n\")\n",
    "print(vector_content)\n",
    "print(\"Document Retrieval Scores:\")\n",
    "print(vector_result[\"chunkdetails\"])\n",
    "\n",
    "print()\n",
    "print(\"************************************************\")\n",
    "print(f\"This is Hybrid (Vector + Keyword Search) response \\t processing time: {predict_time:.3f} s\\n\")\n",
    "print(hybrid_content)\n",
    "print(\"Document Retrieval Scores:\")\n",
    "print(hybrid_result[\"chunkdetails\"])\n",
    "\n",
    "print(\"************************************************\")\n",
    "print(f\"This is HybridCypherRetriever Response \\n\")\n",
    "print(hybridcypher_response.answer)\n",
    "print(\"Document Retrieval Scores:\")\n",
    "print(hybridcypher_chunkdetails[0])\n",
    "\n",
    "print(\"************************************************\")\n",
    "\n",
    "\n",
    "# Extract chunks of text retrieved via different \n",
    "vector_chunk_context = []\n",
    "hybrid_chunk_context = []\n",
    "hybridcypher_chunk_context = []\n",
    "\n",
    "# OPTIONAL: Utilize getChunkDetails to list ref\n",
    "# for fileName,context,score,id in getChunkDetails(vector_result[\"chunkdetails\"]):\n",
    "#     print(f\"{fileName} \\t score:{score}\")\n",
    "#     print(f\"{context} \\n\")\n",
    "#     vector_chunk_context.append(context)\n",
    "\n",
    "# for fileName,context,score,id in getChunkDetails(hybrid_result[\"chunkdetails\"]):\n",
    "#     print(f\"{fileName} \\t score:{score}\")\n",
    "#     print(f\"{context} \\n\")\n",
    "#     hybrid_chunk_context.append(context)\n",
    "\n",
    "print(\"************************************************\")\n",
    "for fileName,context,score,id in getChunkDetails(vector_result[\"chunkdetails\"]):\n",
    "    print(f\"{fileName} \\t score:{score}\")\n",
    "    print(f\"{context} \\n\")\n",
    "    vector_chunk_context.append(context)\n",
    "\n",
    "print(\"************************************************\")\n",
    "for fileName,context,score,id in getChunkDetails(hybrid_result[\"chunkdetails\"]):\n",
    "    print(f\"{fileName} \\t score:{score}\")\n",
    "    print(f\"{context} \\n\")\n",
    "    hybrid_chunk_context.append(context)\n",
    "\n",
    "print(\"************************************************\")\n",
    "for fileName,context,score,id in getChunkDetails(hybridcypher_chunkdetails[0]):\n",
    "    print(f\"{fileName} \\t score:{score}\")\n",
    "    print(f\"{context} \\n\")\n",
    "    hybridcypher_chunk_context.append(context)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: Thresholds for similarity score (i.e default is 0.5) for document retrieval to ensure they are relevant to the query overall\n",
    "However, in addition to general relevance scores, the Neo4J llm graph builder checks if specific terms or entities directly related to the query are present in the retrieved document. If a document scores highly but doesn't contain key terms or specific entities tied to the query, a fallback response may be triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['of the basilar artery all become the\\xa0circle of Willis, a confluence of arter‐ ies that can maintain perfusion of the brain even if narrowing or a block‐ age limits flow through one part (Figure\\xa01). Watch this\\xa0animation\\xa0to see how blood flows to the brain and passes through the circle of Willis before being distributed through the cerebrum. The circle of Willis is a specialized arrange‐ ment of arteries that ensure constant perfusion of the cerebrum even in the event of a blockage of one of the arteries in the circle. The animation shows the normal direction of flow through the cir‐ cle of Willis to the middle cerebral artery. Where would the blood come from if there were a blockage just posterior to the middle cerebral artery on the left? Venous Return After passing through the CNS, blood returns to the circulation through a series of\\xa0dural sinuses\\xa0and veins (Figure\\xa02). The\\xa0superior sagittal si‐ n', 'Figure\\xa01.\\xa0Circle of Willis. The blood supply to the brain enters through the internal carotid arteries and the vertebral arteries, eventually giving rise to the circle of Willis. Arterial Supply The major artery carrying recently oxygenated blood away from the heart is the aorta. The very first branches off the aorta supply the heart with nutrients and oxygen. The next branches give rise to the\\xa0common carotid arteries, which further branch into the\\xa0in‐ ternal carotid arteries. The exter‐ nal carotid arteries supply blood to the tissues on the surface of the cranium. The bases of the common carotids contain stretch receptors that immediately re‐ spond to the drop in blood pres‐ sure upon standing. The\\xa0ortho‐ static reflex\\xa0is a reaction to this change in body position, so that blood pressure is maintained against the increasing effect of gravity (orthostatic means “stand‐ ing up', 'choroid plexus: specialized structures containing ependymal cells lining blood capillaries that filter blood to produce CSF in the four ventricles of the brain circle of Willis: unique anatomical arrangement of blood vessels around the base of the brain that maintains perfusion of blood into the brain even if one component of the structure is blocked or narrowed common carotid artery: blood vessel that branches off the aorta (or the brachiocephalic artery on the right) and supplies blood to the head and neck corpus callosum: large white matter structure that connects the right and left cerebral hemispheres cranial nerve ganglion: sensory ganglion of cranial nerves cranial nerve: one of twelve nerves connected to the brain that are re‐ sponsible for sensory or motor functions of the head and neck descending tract: central nervous system fibers carrying motor com‐ mands from the brain to the spinal cord or periphery diencephalon: region of the', ' pressure is maintained against the increasing effect of gravity (orthostatic means “stand‐ ing up”). Heart rate increases—a reflex of the sympathetic division of the autonomic nervous system—and this raises blood pressure. The internal carotid artery enters the cranium through the\\xa0carotid canal\\xa0in the temporal bone. A second set of vessels that supply the CNS are the\\xa0vertebral arteries, which are protected as they pass through the neck region by the transverse foramina of the cervical vertebrae. The vertebral arteries enter the cranium through the\\xa0foramen magnum\\xa0of the occipital bone. Branches off the left and right vertebral arteries merge into the\\xa0anterior spinal artery\\xa0supplying the anterior aspect of the spinal cord, found along the anterior median fissure. The two vertebral arteries then merge into the\\xa0basilar artery, which gives rise to branches to the brain stem and cerebellum. The left']\n",
      "['of the basilar artery all become the\\xa0circle of Willis, a confluence of arter‐ ies that can maintain perfusion of the brain even if narrowing or a block‐ age limits flow through one part (Figure\\xa01). Watch this\\xa0animation\\xa0to see how blood flows to the brain and passes through the circle of Willis before being distributed through the cerebrum. The circle of Willis is a specialized arrange‐ ment of arteries that ensure constant perfusion of the cerebrum even in the event of a blockage of one of the arteries in the circle. The animation shows the normal direction of flow through the cir‐ cle of Willis to the middle cerebral artery. Where would the blood come from if there were a blockage just posterior to the middle cerebral artery on the left? Venous Return After passing through the CNS, blood returns to the circulation through a series of\\xa0dural sinuses\\xa0and veins (Figure\\xa02). The\\xa0superior sagittal si‐ n', 'Figure\\xa01.\\xa0Circle of Willis. The blood supply to the brain enters through the internal carotid arteries and the vertebral arteries, eventually giving rise to the circle of Willis. Arterial Supply The major artery carrying recently oxygenated blood away from the heart is the aorta. The very first branches off the aorta supply the heart with nutrients and oxygen. The next branches give rise to the\\xa0common carotid arteries, which further branch into the\\xa0in‐ ternal carotid arteries. The exter‐ nal carotid arteries supply blood to the tissues on the surface of the cranium. The bases of the common carotids contain stretch receptors that immediately re‐ spond to the drop in blood pres‐ sure upon standing. The\\xa0ortho‐ static reflex\\xa0is a reaction to this change in body position, so that blood pressure is maintained against the increasing effect of gravity (orthostatic means “stand‐ ing up', 'choroid plexus: specialized structures containing ependymal cells lining blood capillaries that filter blood to produce CSF in the four ventricles of the brain circle of Willis: unique anatomical arrangement of blood vessels around the base of the brain that maintains perfusion of blood into the brain even if one component of the structure is blocked or narrowed common carotid artery: blood vessel that branches off the aorta (or the brachiocephalic artery on the right) and supplies blood to the head and neck corpus callosum: large white matter structure that connects the right and left cerebral hemispheres cranial nerve ganglion: sensory ganglion of cranial nerves cranial nerve: one of twelve nerves connected to the brain that are re‐ sponsible for sensory or motor functions of the head and neck descending tract: central nervous system fibers carrying motor com‐ mands from the brain to the spinal cord or periphery diencephalon: region of the', ' pressure is maintained against the increasing effect of gravity (orthostatic means “stand‐ ing up”). Heart rate increases—a reflex of the sympathetic division of the autonomic nervous system—and this raises blood pressure. The internal carotid artery enters the cranium through the\\xa0carotid canal\\xa0in the temporal bone. A second set of vessels that supply the CNS are the\\xa0vertebral arteries, which are protected as they pass through the neck region by the transverse foramina of the cervical vertebrae. The vertebral arteries enter the cranium through the\\xa0foramen magnum\\xa0of the occipital bone. Branches off the left and right vertebral arteries merge into the\\xa0anterior spinal artery\\xa0supplying the anterior aspect of the spinal cord, found along the anterior median fissure. The two vertebral arteries then merge into the\\xa0basilar artery, which gives rise to branches to the brain stem and cerebellum. The left']\n",
      "['of the basilar artery all become the\\xa0circle of Willis, a confluence of arter‐ ies that can maintain perfusion of the brain even if narrowing or a block‐ age limits flow through one part (Figure\\xa01). Watch this\\xa0animation\\xa0to see how blood flows to the brain and passes through the circle of Willis before being distributed through the cerebrum. The circle of Willis is a specialized arrange‐ ment of arteries that ensure constant perfusion of the cerebrum even in the event of a blockage of one of the arteries in the circle. The animation shows the normal direction of flow through the cir‐ cle of Willis to the middle cerebral artery. Where would the blood come from if there were a blockage just posterior to the middle cerebral artery on the left? Venous Return After passing through the CNS, blood returns to the circulation through a series of\\xa0dural sinuses\\xa0and veins (Figure\\xa02). The\\xa0superior sagittal si‐ n', 'Figure\\xa01.\\xa0Circle of Willis. The blood supply to the brain enters through the internal carotid arteries and the vertebral arteries, eventually giving rise to the circle of Willis. Arterial Supply The major artery carrying recently oxygenated blood away from the heart is the aorta. The very first branches off the aorta supply the heart with nutrients and oxygen. The next branches give rise to the\\xa0common carotid arteries, which further branch into the\\xa0in‐ ternal carotid arteries. The exter‐ nal carotid arteries supply blood to the tissues on the surface of the cranium. The bases of the common carotids contain stretch receptors that immediately re‐ spond to the drop in blood pres‐ sure upon standing. The\\xa0ortho‐ static reflex\\xa0is a reaction to this change in body position, so that blood pressure is maintained against the increasing effect of gravity (orthostatic means “stand‐ ing up', ' pressure is maintained against the increasing effect of gravity (orthostatic means “stand‐ ing up”). Heart rate increases—a reflex of the sympathetic division of the autonomic nervous system—and this raises blood pressure. The internal carotid artery enters the cranium through the\\xa0carotid canal\\xa0in the temporal bone. A second set of vessels that supply the CNS are the\\xa0vertebral arteries, which are protected as they pass through the neck region by the transverse foramina of the cervical vertebrae. The vertebral arteries enter the cranium through the\\xa0foramen magnum\\xa0of the occipital bone. Branches off the left and right vertebral arteries merge into the\\xa0anterior spinal artery\\xa0supplying the anterior aspect of the spinal cord, found along the anterior median fissure. The two vertebral arteries then merge into the\\xa0basilar artery, which gives rise to branches to the brain stem and cerebellum. The left']\n"
     ]
    }
   ],
   "source": [
    "print(vector_chunk_context)\n",
    "print(hybrid_chunk_context)\n",
    "print(hybridcypher_chunk_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'id': 'df99f8192bf2961d93f8fa02eb32337088dbef...</td>\n",
       "      <td>{'id': 'f73ae203cb7d3238826460d93b4dcbef24801c...</td>\n",
       "      <td>{'id': '8eee3b357209bc21f61d633156b9d00b829ddc...</td>\n",
       "      <td>{'id': '24564789b83b665072530bcf37943ede49aa12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'id': 'df99f8192bf2961d93f8fa02eb32337088dbef...</td>\n",
       "      <td>{'id': 'f73ae203cb7d3238826460d93b4dcbef24801c...</td>\n",
       "      <td>{'id': '8eee3b357209bc21f61d633156b9d00b829ddc...</td>\n",
       "      <td>{'id': '24564789b83b665072530bcf37943ede49aa12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'id': 'df99f8192bf2961d93f8fa02eb32337088dbef...</td>\n",
       "      <td>{'id': 'f73ae203cb7d3238826460d93b4dcbef24801c...</td>\n",
       "      <td>{'id': '8eee3b357209bc21f61d633156b9d00b829ddc...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  {'id': 'df99f8192bf2961d93f8fa02eb32337088dbef...   \n",
       "1  {'id': 'df99f8192bf2961d93f8fa02eb32337088dbef...   \n",
       "2  {'id': 'df99f8192bf2961d93f8fa02eb32337088dbef...   \n",
       "\n",
       "                                                   1  \\\n",
       "0  {'id': 'f73ae203cb7d3238826460d93b4dcbef24801c...   \n",
       "1  {'id': 'f73ae203cb7d3238826460d93b4dcbef24801c...   \n",
       "2  {'id': 'f73ae203cb7d3238826460d93b4dcbef24801c...   \n",
       "\n",
       "                                                   2  \\\n",
       "0  {'id': '8eee3b357209bc21f61d633156b9d00b829ddc...   \n",
       "1  {'id': '8eee3b357209bc21f61d633156b9d00b829ddc...   \n",
       "2  {'id': '8eee3b357209bc21f61d633156b9d00b829ddc...   \n",
       "\n",
       "                                                   3  \n",
       "0  {'id': '24564789b83b665072530bcf37943ede49aa12...  \n",
       "1  {'id': '24564789b83b665072530bcf37943ede49aa12...  \n",
       "2                                               None  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = (vector_result[\"chunkdetails\"],hybrid_result[\"chunkdetails\"],hybridcypher_chunkdetails[0])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b43bd25125546b4b083cf29026963c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RAGAS (default OpenAI)\n",
    "from ragas import EvaluationDataset, SingleTurnSample, evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    answer_similarity,\n",
    "    answer_correctness\n",
    ")\n",
    "\n",
    "# Define metrics to evaluate\n",
    "metrics=[\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        answer_similarity,\n",
    "        faithfulness,\n",
    "        answer_correctness,\n",
    "        answer_relevancy,\n",
    "    ]\n",
    "\n",
    "# Set ground context and ground truth\n",
    "# reference_contexts=[\"circle of Willis: unique anatomical arrangement of blood vessels around the base of the brain that maintains perfusion of blood into the brain even if one component of the structure is blocked or narrowed\"]\n",
    "# reference_answer=\"Circle of Willis is an unique anatomical arrangement of blood vessels around the base of the brain that maintains perfusion of blood into the brain even if one component of the structure is blocked or narrowed\"\n",
    "\n",
    "rubric = {\n",
    "        \"accuracy\": \"Correct\",\n",
    "        \"completeness\": \"High\",\n",
    "        \"fluency\":\"Excellent\"\n",
    "    }    \n",
    "\n",
    "# Set ground context and ground_truth (i.e what are all the )\n",
    "reference_contexts=[\"Branches off the left and right vertebral arteries merge into the anterior spinal artery supplying the anterior aspect of the spinal cord, found along the anterior median fissure. The two vertebral arteries then merge into the basilar artery, which gives rise to branches to the brain stem and cerebellum. The left and right internal carotid arteries and branches of the basilar artery all become the circle of Willis, a confluence of arter‐ies that can maintain perfusion of the brain even if narrowing or a block‐age limits flow through one part (Figure 1).\", \"The circle of Willis is a specialized arrange‐ ment of arteries that ensure constant perfusion of the cerebrum even in the event of a blockage of one of the arteries in the circle. The animation shows the normal direction of flow through the cir‐cle of Willis to the middle cerebral artery. Where would the blood come from if there were a blockage just posterior to the middle cerebral artery on the left?\"]\n",
    "reference_answer=\"internal carotid arteries, vertebral arties, basilar artery\"\n",
    "\n",
    "# Vector Response\n",
    "sample_vector_retrieval = SingleTurnSample(\n",
    "    user_input=question,\n",
    "    retrieved_contexts=vector_chunk_context,\n",
    "    reference_contexts=reference_contexts,\n",
    "    response=vector_content,\n",
    "    reference=reference_answer,\n",
    "    rubric=rubric\n",
    ")\n",
    "\n",
    "# Hybrid (vector+keyword) Response \n",
    "sample_hybrid_retrieval = SingleTurnSample(\n",
    "    user_input=question,\n",
    "    retrieved_contexts=hybrid_chunk_context,\n",
    "    reference_contexts=reference_contexts,\n",
    "    response=hybrid_content,\n",
    "    reference=reference_answer,\n",
    "    rubric=rubric\n",
    ")\n",
    "\n",
    "# HybridCypher Response only\n",
    "sample_hybridCypher_retrieval = SingleTurnSample(\n",
    "    user_input=question,\n",
    "    retrieved_contexts=hybridcypher_chunk_context,\n",
    "    reference_contexts=reference_contexts,\n",
    "    response=hybridcypher_response.answer,\n",
    "    reference=reference_answer,\n",
    "    rubric=rubric\n",
    ")\n",
    "\n",
    "\n",
    "ds = EvaluationDataset([sample_vector_retrieval, sample_hybrid_retrieval, sample_hybridCypher_retrieval])\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=ds,\n",
    "    metrics = metrics\n",
    ")\n",
    "\n",
    "result = result.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAGAS Metrics \n",
    "**Contextual_Precision**: Measures quality of retrieved results. A ratio of the number of relevant chunks to the total number of k chunks. Utilizes an LLM to determine if retrieved chunks of text are relevant, given a reference context\n",
    "\n",
    "$\\text{Context Precision @ K} = \\frac{\\sum_{k=1}^{K} (\\text{Precision@K} \\times v_k)}{\\text{Total number of relevant items in the top K results}}$\n",
    "\n",
    "**Contextual_Recall**: Measures completeness of retrieved results. Computed using user_input, reference (ground truth) answer, and retrieved_contexts with values range between 0 and 1 with higher values indicating better performance. This metric uses reference (ground truth) answer as a proxy to reference_contexts which also makes it easier to use as annotating reference context verus the traditional Non-LLM methods.\n",
    "\n",
    "$\\text{Context Recall} = \\frac{|\\text{Ground Truth claims that can be attributed to context}|}{|\\text{Number of claims in GT}|}$\n",
    "\n",
    "**Semantic Similarity**: Evaluation based on reference ground truth and answer. This evaluation utilizes a cross-encoder model to calculate the encoder (utilizes cosine similarity) \n",
    "\n",
    "$\n",
    "\\text{Cosine Similarity}(A, B) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|}\n",
    "$\n",
    "\n",
    "\n",
    "**Answer Relevancy**: Measures how pertinent the generated question is to the given question. This is computed by generated a number of artifical questions based on the answer and measuring the similarity between the original question and those artificial questions.\n",
    "\n",
    "The assessment of Answer Correctness involves gauging the accuracy of the generated answer when compared to the ground truth. This evaluation relies on the ground truth and the answer, with scores ranging from 0 to 1. A higher score indicates a closer alignment between the generated answer and the ground truth, signifying better correctness.\n",
    "\n",
    "Answer correctness encompasses two critical aspects: semantic similarity between the generated answer and the ground truth, as well as factual similarity. These aspects are combined using a weighted scheme to formulate the answer correctness score. Users also have the option to employ a 'threshold' value to round the resulting score to binary, if desired.\n",
    "\n",
    "\n",
    "$\\text{Answer Relevancy} = \\frac{1}{N}\\sum_{i=1}^{N}cos(E_g,E_o)$\n",
    "\n",
    "where:\n",
    "\n",
    " - $E_g$ is the embedding of the generated question.\n",
    " - $E_o$ is the embedding of the original question.\n",
    " - $N$ is the number of generated questions, which is 3 default.\n",
    "\n",
    "**Answer correctness**: Measures how accurate the generated answer is relative to a \"golden\" answer that is deemed to be the correct answer. It is based on weighted sum of factual consistency (F1 Score) and the semantic similarity between the ground-truth answer and the generated response.\n",
    "\n",
    "$\\text{Answer Correctness} = w_1 \\times \\text{F1-score} + w_2 \\times \\text{Semantic Similarity}$\n",
    "\n",
    "where:\n",
    "- $\\text{F1-score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$\n",
    "- $\\text{semantic similarity} = \\text{cosine similarity}(A, B) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|}$\n",
    "\n",
    "\n",
    "\n",
    "**Faithfulness**: Measures the factual consistency of the generated answer against given context. The answer is regraded as faithful if all the claims made in the answer can be inferred form the given context. To calculate this, a set of claims from the generated answer is first identified. Then each of these claims is cross-checked with the given context to determine if it can be inferred from the context. Uses an LLM-as-a-judge approach.\n",
    "\n",
    "$Faithfulness = \\frac{|\\text{Number of claims in the generated answer that can be inferred from the given answer}|}{|\\text{Total Number of claims in generated answer}|}$\n",
    "\n",
    "***NOTE***: default llm is OpenAI. Requires LLM wrapper to utilize other langchain wrappers\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>rubric</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are all the arteries in the Circle of Willis</td>\n",
       "      <td>[of the basilar artery all become the circle o...</td>\n",
       "      <td>[Branches off the left and right vertebral art...</td>\n",
       "      <td>The Circle of Willis is a ring-shaped structur...</td>\n",
       "      <td>internal carotid arteries, vertebral arties, b...</td>\n",
       "      <td>{'accuracy': 'Correct', 'completeness': 'High'...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.861038</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.871509</td>\n",
       "      <td>0.910007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are all the arteries in the Circle of Willis</td>\n",
       "      <td>[of the basilar artery all become the circle o...</td>\n",
       "      <td>[Branches off the left and right vertebral art...</td>\n",
       "      <td>The Circle of Willis is a network of arteries ...</td>\n",
       "      <td>internal carotid arteries, vertebral arties, b...</td>\n",
       "      <td>{'accuracy': 'Correct', 'completeness': 'High'...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.870456</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.717614</td>\n",
       "      <td>0.920072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are all the arteries in the Circle of Willis</td>\n",
       "      <td>[of the basilar artery all become the circle o...</td>\n",
       "      <td>[Branches off the left and right vertebral art...</td>\n",
       "      <td>The arteries that contribute to the Circle of ...</td>\n",
       "      <td>internal carotid arteries, vertebral arties, b...</td>\n",
       "      <td>{'accuracy': 'Correct', 'completeness': 'High'...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.893706</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.973427</td>\n",
       "      <td>0.958501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What are all the arteries in the Circle of Willis   \n",
       "1  What are all the arteries in the Circle of Willis   \n",
       "2  What are all the arteries in the Circle of Willis   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [of the basilar artery all become the circle o...   \n",
       "1  [of the basilar artery all become the circle o...   \n",
       "2  [of the basilar artery all become the circle o...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [Branches off the left and right vertebral art...   \n",
       "1  [Branches off the left and right vertebral art...   \n",
       "2  [Branches off the left and right vertebral art...   \n",
       "\n",
       "                                            response  \\\n",
       "0  The Circle of Willis is a ring-shaped structur...   \n",
       "1  The Circle of Willis is a network of arteries ...   \n",
       "2  The arteries that contribute to the Circle of ...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  internal carotid arteries, vertebral arties, b...   \n",
       "1  internal carotid arteries, vertebral arties, b...   \n",
       "2  internal carotid arteries, vertebral arties, b...   \n",
       "\n",
       "                                              rubric  context_precision  \\\n",
       "0  {'accuracy': 'Correct', 'completeness': 'High'...                0.0   \n",
       "1  {'accuracy': 'Correct', 'completeness': 'High'...                0.0   \n",
       "2  {'accuracy': 'Correct', 'completeness': 'High'...                0.0   \n",
       "\n",
       "   context_recall  semantic_similarity  faithfulness  answer_correctness  \\\n",
       "0             1.0             0.861038      0.437500            0.871509   \n",
       "1             1.0             0.870456      0.666667            0.717614   \n",
       "2             1.0             0.893706      0.333333            0.973427   \n",
       "\n",
       "   answer_relevancy  \n",
       "0          0.910007  \n",
       "1          0.920072  \n",
       "2          0.958501  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.861038</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.871509</td>\n",
       "      <td>0.910007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.870456</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.717614</td>\n",
       "      <td>0.920072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.893706</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.973427</td>\n",
       "      <td>0.958501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   semantic_similarity  faithfulness  answer_correctness  answer_relevancy\n",
       "0             0.861038      0.437500            0.871509          0.910007\n",
       "1             0.870456      0.666667            0.717614          0.920072\n",
       "2             0.893706      0.333333            0.973427          0.958501"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_plotted = ['semantic_similarity','faithfulness','answer_correctness','answer_relevancy']\n",
    "\n",
    "result[metrics_plotted]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple QA and Retrieval Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate df\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the Circle of Willis?\n",
      "I'm sorry, but the provided context does not contain information about the Circle of Willis. \n",
      "\n",
      "What are all the arteries in the Circle of Willis?\n",
      "The Circle of Willis is a ring-shaped structure of arteries at the base of the brain. It is formed by the following arteries:\n",
      "\n",
      "* **Internal carotid arteries:** These arteries branch from the common carotid arteries and enter the skull through the carotid canal.\n",
      "* **Anterior cerebral arteries:** These arteries arise from the internal carotid arteries and supply the medial and anterior portions of the frontal and parietal lobes.\n",
      "* **Anterior communicating artery:** This small artery connects the two anterior cerebral arteries.\n",
      "* **Posterior cerebral arteries:** These arteries arise from the basilar artery and supply the posterior portions of the brain, including the occipital lobes and the temporal lobes.\n",
      "* **Posterior communicating arteries:** These arteries connect the internal carotid arteries to the posterior cerebral arteries.\n",
      "* **Basilar artery:** This artery is formed by the union of the two vertebral arteries and supplies the brainstem and cerebellum. \n",
      "\n",
      "Why is there a barrier between the central nervous system and the blood supply?\n",
      "The barrier between the central nervous system (CNS) and the blood supply, known as the blood-brain barrier, exists to protect the delicate brain and spinal cord from harmful substances in the bloodstream. This barrier is crucial because the CNS is highly sensitive to toxins, pathogens, and fluctuations in blood composition. \n",
      "\n",
      "The blood-brain barrier acts as a selective filter, allowing essential nutrients and oxygen to pass through while blocking potentially harmful substances. This protection ensures the optimal functioning of the CNS and prevents damage that could lead to neurological disorders. \n",
      "\n",
      "How is the pia mater connected with the central nervous system?\n",
      "The pia mater is a thin, delicate membrane that directly adheres to the surface of the central nervous system (CNS). It's like a thin, protective layer that follows the contours of the brain and spinal cord, extending into every convolution and groove. This close connection allows the pia mater to provide a gentle covering and support for the delicate tissues of the CNS. \n",
      "\n",
      "How many ventricles exist and how are they connected?\n",
      "There are four ventricles in the brain: two lateral ventricles, the third ventricle, and the fourth ventricle. \n",
      "\n",
      "* The **lateral ventricles** are located deep within the cerebrum and are connected to the **third ventricle** by two openings called the **interventricular foramina**. \n",
      "* The **third ventricle** is situated between the left and right sides of the diencephalon and opens into the **cerebral aqueduct**, which passes through the midbrain. \n",
      "* The **cerebral aqueduct** then opens into the **fourth ventricle**, which is located between the cerebellum and the pons and upper medulla. \n",
      "\n",
      "What happens when there is not enough oxygen to the brain?\n",
      "When there is not enough oxygen to the brain, it can lead to a condition called **hypoxia**. This can cause a range of problems, from mild cognitive impairment to severe brain damage and even death. \n",
      "\n",
      "The brain requires a constant supply of oxygen to function properly. Without oxygen, brain cells cannot produce energy and begin to die. The severity of the damage depends on how long the brain is deprived of oxygen. \n",
      "\n",
      "Some symptoms of hypoxia include:\n",
      "\n",
      "* Dizziness\n",
      "* Confusion\n",
      "* Headache\n",
      "* Seizures\n",
      "* Loss of consciousness\n",
      "\n",
      "If you suspect someone is experiencing hypoxia, it is important to seek medical attention immediately. \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62fc03fd30746ed875e54d6f8f855be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from src.QA_integration_new import (\n",
    "    format_documents,\n",
    "    get_rag_chain,\n",
    "    get_sources_and_chunks,\n",
    "    get_total_tokens,\n",
    "    create_document_retriever_chain,\n",
    "    retrieve_documents\n",
    ")\n",
    "from src.llm import get_llm\n",
    "from src.shared.constants import VECTOR_SEARCH_QUERY, CHAT_SEARCH_KWARG_SCORE_THRESHOLD\n",
    "from langchain_community.vectorstores.neo4j_vector import Neo4jVector\n",
    "from langchain_core.messages import HumanMessage\n",
    "from ragas import SingleTurnSample\n",
    "\n",
    "# Set model and load ground truth QA pairs\n",
    "model = \"gemini-1.5-flash-001\"\n",
    "qa_df = pd.read_csv(\"graphrag_qa_groundtruth.csv\")\n",
    "\n",
    "# Initialize variables\n",
    "ragas_sample_list = []\n",
    "llm, model_name = get_llm(model)\n",
    "score_threshold = CHAT_SEARCH_KWARG_SCORE_THRESHOLD\n",
    "\n",
    "# Define evaluation rubric\n",
    "rubric = {\n",
    "    \"accuracy\": \"Correct\",\n",
    "    \"completeness\": \"High\",\n",
    "    \"fluency\": \"Excellent\"\n",
    "}\n",
    "\n",
    "# Create vector retriever\n",
    "neo_db = Neo4jVector.from_existing_index(\n",
    "    embedding=EMBEDDING_FUNCTION,\n",
    "    index_name=\"vector\",\n",
    "    retrieval_query=VECTOR_SEARCH_QUERY,\n",
    "    graph=graph\n",
    ")\n",
    "retriever = neo_db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"score_threshold\": score_threshold}\n",
    ")\n",
    "doc_retriever = create_document_retriever_chain(llm, retriever)\n",
    "\n",
    "# Iterate through each question-answer pair\n",
    "for index, row in qa_df.iterrows():\n",
    "    # Create messages and retrieve documents\n",
    "    messages = [HumanMessage(content=row[\"question\"])]\n",
    "    docs = retrieve_documents(doc_retriever, messages)\n",
    "\n",
    "    if docs:\n",
    "        formatted_docs, sources = format_documents(docs, model)\n",
    "        rag_chain = get_rag_chain(llm=llm)\n",
    "        ai_response = rag_chain.invoke({\n",
    "            \"messages\": messages,\n",
    "            \"context\": formatted_docs,\n",
    "            \"input\": row[\"question\"]  # Use row[\"question\"] instead of undefined variable\n",
    "        })\n",
    "        result = get_sources_and_chunks(sources, docs)\n",
    "        content = ai_response.content\n",
    "        total_tokens = get_total_tokens(ai_response, llm)\n",
    "    else:\n",
    "        content = \"I couldn't find any relevant documents to answer your question.\"\n",
    "        result = {\"sources\": [], \"chunkdetails\": []}\n",
    "        total_tokens = 0\n",
    "    print(row[\"question\"])\n",
    "    print(content)\n",
    "    # Gather retrieved context details\n",
    "    retrieved_contexts = [context for _, context, _, _ in getChunkDetails(result[\"chunkdetails\"])]\n",
    "\n",
    "    # Create RAGAS SingleTurnSample\n",
    "    sample = SingleTurnSample(\n",
    "        user_input=str(row[\"question\"]),\n",
    "        retrieved_contexts=retrieved_contexts,\n",
    "        reference_contexts=[row[\"reference_contexts\"]],\n",
    "        response=content,\n",
    "        reference=str(row[\"reference_answer\"]),\n",
    "        rubric=rubric\n",
    "    )\n",
    "\n",
    "    # Append sample to the list\n",
    "    ragas_sample_list.append(sample)\n",
    "\n",
    "# Evaluate the dataset and merge results\n",
    "ds = EvaluationDataset(ragas_sample_list)\n",
    "result = evaluate(dataset=ds, metrics=metrics)\n",
    "result = result.to_pandas()\n",
    "result[\"retrieval_type\"] = \"vector\"\n",
    "\n",
    "# Combine results with existing DataFrame\n",
    "df = pd.concat([df, result], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: 'CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 740} for query: 'CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the Circle of Willis?\n",
      "The Circle of Willis is a specialized arrangement of arteries at the base of the brain that ensures constant blood flow to the cerebrum, even if there is a blockage in one of the arteries. It's a confluence of arteries that can maintain perfusion of the brain even if narrowing or a blockage limits flow through one part. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: 'CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 740} for query: 'CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are all the arteries in the Circle of Willis?\n",
      "The Circle of Willis is a ring-shaped structure of arteries at the base of the brain. It is formed by the following arteries:\n",
      "\n",
      "* **Internal carotid arteries:** These arteries enter the skull through the carotid canal and branch into the anterior cerebral artery and the middle cerebral artery.\n",
      "* **Anterior cerebral arteries:** These arteries supply blood to the frontal lobes and parts of the parietal lobes.\n",
      "* **Middle cerebral arteries:** These arteries supply blood to the lateral surfaces of the cerebral hemispheres.\n",
      "* **Posterior cerebral arteries:** These arteries supply blood to the occipital lobes and parts of the temporal lobes.\n",
      "* **Posterior communicating arteries:** These arteries connect the internal carotid arteries to the posterior cerebral arteries.\n",
      "* **Anterior communicating artery:** This artery connects the two anterior cerebral arteries.\n",
      "* **Basilar artery:** This artery is formed by the merging of the two vertebral arteries and gives rise to branches to the brainstem and cerebellum. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: 'CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 740} for query: 'CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why is there a barrier between the central nervous system and the blood supply?\n",
      "The barrier between the central nervous system (CNS) and the blood supply, known as the blood-brain barrier, exists to protect the delicate brain and spinal cord from harmful substances in the bloodstream. This barrier is crucial because the CNS is highly sensitive to toxins, pathogens, and fluctuations in blood composition. \n",
      "\n",
      "The blood-brain barrier acts as a selective filter, allowing essential nutrients and oxygen to pass through while blocking potentially harmful substances. This protection ensures the optimal functioning of the CNS and prevents damage that could lead to neurological disorders. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: 'CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 740} for query: 'CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How is the pia mater connected with the central nervous system?\n",
      "The pia mater is directly adjacent to the surface of the central nervous system (CNS). It's a thin fibrous membrane that closely follows the convolutions of the gyri and sulci in the cerebral cortex, as well as other grooves and indentations. This close adherence means the pia mater essentially envelops the CNS, providing a delicate and protective covering. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: 'CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 740} for query: 'CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many ventricles exist and how are they connected?\n",
      "There are four ventricles within the brain: two lateral ventricles, the third ventricle, and the fourth ventricle. \n",
      "\n",
      "* The **lateral ventricles** are located deep within the cerebrum and are connected to the **third ventricle** by two openings called the **interventricular foramina**. \n",
      "* The **third ventricle** is situated between the left and right sides of the diencephalon and opens into the **cerebral aqueduct**, which passes through the midbrain. \n",
      "* The **cerebral aqueduct** then opens into the **fourth ventricle**, which is located between the cerebellum and the pons and upper medulla. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: 'CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 740} for query: 'CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What happens when there is not enough oxygen to the brain?\n",
      "When there is not enough oxygen to the brain, it can lead to a condition called **hypoxia**. This can cause a range of problems, from mild cognitive impairment to severe brain damage and even death. \n",
      "\n",
      "The brain requires a constant supply of oxygen to function properly. Without oxygen, brain cells begin to die. The severity of the damage depends on how long the brain is deprived of oxygen. \n",
      "\n",
      "Here are some of the effects of hypoxia:\n",
      "\n",
      "* **Confusion and disorientation:**  The brain may not be able to process information correctly, leading to confusion and difficulty thinking clearly.\n",
      "* **Dizziness and headaches:**  These symptoms can occur due to the brain's inability to function properly.\n",
      "* **Seizures:**  In severe cases, hypoxia can trigger seizures.\n",
      "* **Coma:**  If the brain is deprived of oxygen for a long time, it can lead to a coma.\n",
      "* **Brain damage:**  Prolonged hypoxia can cause permanent brain damage, leading to long-term disabilities.\n",
      "\n",
      "It's important to note that the effects of hypoxia can vary depending on the individual and the severity of the oxygen deprivation. \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b390aa6b7b4fddbfb3fdaa695f26b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from src.QA_integration_new import (\n",
    "    format_documents,\n",
    "    get_rag_chain,\n",
    "    get_sources_and_chunks,\n",
    "    get_total_tokens,\n",
    "    create_document_retriever_chain,\n",
    "    retrieve_documents\n",
    ")\n",
    "from src.llm import get_llm\n",
    "from src.shared.constants import VECTOR_SEARCH_QUERY, CHAT_SEARCH_KWARG_SCORE_THRESHOLD\n",
    "from langchain_community.vectorstores.neo4j_vector import Neo4jVector\n",
    "from langchain_core.messages import HumanMessage\n",
    "from ragas import SingleTurnSample\n",
    "\n",
    "# Set model and load ground truth QA pairs\n",
    "model = \"gemini-1.5-flash-001\"\n",
    "qa_df = pd.read_csv(\"graphrag_qa_groundtruth.csv\")\n",
    "\n",
    "# Initialize variables\n",
    "ragas_sample_list = []\n",
    "llm, model_name = get_llm(model)\n",
    "score_threshold = CHAT_SEARCH_KWARG_SCORE_THRESHOLD\n",
    "\n",
    "# Define evaluation rubric\n",
    "rubric = {\n",
    "    \"accuracy\": \"Correct\",\n",
    "    \"completeness\": \"High\",\n",
    "    \"fluency\": \"Excellent\"\n",
    "}\n",
    "\n",
    "# Create vector retriever\n",
    "neo_db = Neo4jVector.from_existing_graph(\n",
    "                embedding=EMBEDDING_FUNCTION,\n",
    "                index_name=index_name,\n",
    "                retrieval_query=retrieval_query,\n",
    "                graph=graph,\n",
    "                search_type=\"hybrid\",\n",
    "                node_label=\"Chunk\",\n",
    "                embedding_node_property=\"embedding\",\n",
    "                text_node_properties=[\"text\"],\n",
    "                keyword_index_name=keyword_index\n",
    "                )\n",
    "\n",
    "\n",
    "retriever = neo_db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"score_threshold\": score_threshold}\n",
    ")\n",
    "doc_retriever = create_document_retriever_chain(llm, retriever)\n",
    "\n",
    "# Iterate through each question-answer pair\n",
    "for index, row in qa_df.iterrows():\n",
    "    # Create messages and retrieve documents\n",
    "    messages = [HumanMessage(content=row[\"question\"])]\n",
    "    docs = retrieve_documents(doc_retriever, messages)\n",
    "\n",
    "    if docs:\n",
    "        formatted_docs, sources = format_documents(docs, model)\n",
    "        rag_chain = get_rag_chain(llm=llm)\n",
    "        ai_response = rag_chain.invoke({\n",
    "            \"messages\": messages,\n",
    "            \"context\": formatted_docs,\n",
    "            \"input\": row[\"question\"]  # Use row[\"question\"] instead of undefined variable\n",
    "        })\n",
    "        result = get_sources_and_chunks(sources, docs)\n",
    "        content = ai_response.content\n",
    "        total_tokens = get_total_tokens(ai_response, llm)\n",
    "    else:\n",
    "        content = \"I couldn't find any relevant documents to answer your question.\"\n",
    "        result = {\"sources\": [], \"chunkdetails\": []}\n",
    "        total_tokens = 0\n",
    "    print(row[\"question\"])\n",
    "    print(content)\n",
    "    # Gather retrieved context details\n",
    "    retrieved_contexts = [context for _, context, _, _ in getChunkDetails(result[\"chunkdetails\"])]\n",
    "\n",
    "    # Create RAGAS SingleTurnSample\n",
    "    sample = SingleTurnSample(\n",
    "        user_input=str(row[\"question\"]),\n",
    "        retrieved_contexts=retrieved_contexts,\n",
    "        reference_contexts=[row[\"reference_contexts\"]],\n",
    "        response=content,\n",
    "        reference=str(row[\"reference_answer\"]),\n",
    "        rubric=rubric\n",
    "    )\n",
    "\n",
    "    # Append sample to the list\n",
    "    ragas_sample_list.append(sample)\n",
    "\n",
    "# Evaluate the dataset and merge results\n",
    "ds = EvaluationDataset(ragas_sample_list)\n",
    "result = evaluate(dataset=ds, metrics=metrics)\n",
    "result = result.to_pandas()\n",
    "result[\"retrieval_type\"] = \"hybrid(v+keyword)\"\n",
    "\n",
    "# Combine results with existing DataFrame\n",
    "df = pd.concat([df, result], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Cypher Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 849} for query: 'CALL () { CALL db.index.vector.queryNodes($vector_index_name, $top_k, $query_vector) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS vector_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / vector_index_max_score) AS score UNION CALL db.index.fulltext.queryNodes($fulltext_index_name, $query_text, {limit: $top_k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS ft_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / ft_index_max_score) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $top_k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 849} for query: 'CALL () { CALL db.index.vector.queryNodes($vector_index_name, $top_k, $query_vector) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS vector_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / vector_index_max_score) AS score UNION CALL db.index.fulltext.queryNodes($fulltext_index_name, $query_text, {limit: $top_k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS ft_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / ft_index_max_score) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $top_k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the Circle of Willis?\n",
      "The Circle of Willis is a confluence of arteries that can maintain perfusion of the brain even if narrowing or a blockage limits flow through one part. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 849} for query: 'CALL () { CALL db.index.vector.queryNodes($vector_index_name, $top_k, $query_vector) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS vector_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / vector_index_max_score) AS score UNION CALL db.index.fulltext.queryNodes($fulltext_index_name, $query_text, {limit: $top_k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS ft_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / ft_index_max_score) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $top_k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 849} for query: 'CALL () { CALL db.index.vector.queryNodes($vector_index_name, $top_k, $query_vector) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS vector_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / vector_index_max_score) AS score UNION CALL db.index.fulltext.queryNodes($fulltext_index_name, $query_text, {limit: $top_k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS ft_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / ft_index_max_score) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $top_k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are all the arteries in the Circle of Willis?\n",
      "The Circle of Willis is formed by the confluence of the following arteries: \n",
      "\n",
      "* **Internal carotid arteries:** These arteries enter the cranium through the carotid canal and contribute to the circle. \n",
      "* **Vertebral arteries:** These arteries pass through the neck region and enter the cranium through the foramen magnum. They merge to form the basilar artery.\n",
      "* **Basilar artery:** This artery is formed by the merging of the two vertebral arteries. It gives rise to branches to the brainstem and cerebellum and contributes to the Circle of Willis. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 849} for query: 'CALL () { CALL db.index.vector.queryNodes($vector_index_name, $top_k, $query_vector) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS vector_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / vector_index_max_score) AS score UNION CALL db.index.fulltext.queryNodes($fulltext_index_name, $query_text, {limit: $top_k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS ft_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / ft_index_max_score) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $top_k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 849} for query: 'CALL () { CALL db.index.vector.queryNodes($vector_index_name, $top_k, $query_vector) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS vector_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / vector_index_max_score) AS score UNION CALL db.index.fulltext.queryNodes($fulltext_index_name, $query_text, {limit: $top_k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS ft_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / ft_index_max_score) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $top_k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why is there a barrier between the central nervous system and the blood supply?\n",
      "The blood-brain barrier exists to protect the central nervous system (CNS) from harmful substances that might be circulating in the bloodstream. This barrier is critical because the CNS is highly sensitive and vulnerable to toxins, pathogens, and other potentially damaging elements. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 849} for query: 'CALL () { CALL db.index.vector.queryNodes($vector_index_name, $top_k, $query_vector) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS vector_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / vector_index_max_score) AS score UNION CALL db.index.fulltext.queryNodes($fulltext_index_name, $query_text, {limit: $top_k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS ft_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / ft_index_max_score) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $top_k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 849} for query: 'CALL () { CALL db.index.vector.queryNodes($vector_index_name, $top_k, $query_vector) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS vector_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / vector_index_max_score) AS score UNION CALL db.index.fulltext.queryNodes($fulltext_index_name, $query_text, {limit: $top_k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS ft_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / ft_index_max_score) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $top_k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How is the pia mater connected with the central nervous system?\n",
      "The pia mater is a thin fibrous membrane that directly adjoins the surface of the CNS. It follows the convolutions of the gyri and sulci in the cerebral cortex and fits into other grooves and indentations.  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 849} for query: 'CALL () { CALL db.index.vector.queryNodes($vector_index_name, $top_k, $query_vector) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS vector_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / vector_index_max_score) AS score UNION CALL db.index.fulltext.queryNodes($fulltext_index_name, $query_text, {limit: $top_k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS ft_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / ft_index_max_score) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $top_k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 849} for query: 'CALL () { CALL db.index.vector.queryNodes($vector_index_name, $top_k, $query_vector) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS vector_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / vector_index_max_score) AS score UNION CALL db.index.fulltext.queryNodes($fulltext_index_name, $query_text, {limit: $top_k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS ft_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / ft_index_max_score) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $top_k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many ventricles exist and how are they connected?\n",
      "There are four ventricles within the brain:\n",
      "\n",
      "* **Two lateral ventricles:** These are deep within the cerebrum and are connected to the third ventricle by two openings called the interventricular foramina.\n",
      "* **Third ventricle:** This is the space between the left and right sides of the diencephalon and opens into the cerebral aqueduct.\n",
      "* **Cerebral aqueduct:** This passage connects the third ventricle to the fourth ventricle through the midbrain.\n",
      "* **Fourth ventricle:** This is the space between the cerebellum and the pons and upper medulla. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 849} for query: 'CALL () { CALL db.index.vector.queryNodes($vector_index_name, $top_k, $query_vector) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS vector_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / vector_index_max_score) AS score UNION CALL db.index.fulltext.queryNodes($fulltext_index_name, $query_text, {limit: $top_k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS ft_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / ft_index_max_score) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $top_k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n",
      "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (chunks) { ... }} {position: line: 9, column: 1, offset: 849} for query: 'CALL () { CALL db.index.vector.queryNodes($vector_index_name, $top_k, $query_vector) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS vector_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / vector_index_max_score) AS score UNION CALL db.index.fulltext.queryNodes($fulltext_index_name, $query_text, {limit: $top_k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS ft_index_max_score UNWIND nodes AS n RETURN n.node AS node, (n.score / ft_index_max_score) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $top_k \\nWITH node as chunk, score\\n// find the document of the chunk\\nMATCH (chunk)-[:PART_OF]->(d:Document)\\n\\n// aggregate chunk-details\\nWITH d, collect(DISTINCT {chunk: chunk, score: score}) AS chunks, avg(score) as avg_score\\n// fetch entities\\nCALL { WITH chunks\\nUNWIND chunks as chunkScore\\nWITH chunkScore.chunk as chunk\\n// entities connected to the chunk\\n// todo only return entities that are actually in the chunk, remember we connect all extracted entities to all chunks\\n// todo sort by relevancy (embeddding comparision?) cut off after X (e.g. 25) nodes?\\nOPTIONAL MATCH (chunk)-[:HAS_ENTITY]->(e)\\nWITH e, count(*) as numChunks \\nORDER BY numChunks DESC LIMIT 25\\n// depending on match to query embedding either 1 or 2 step expansion\\nWITH CASE WHEN true // vector.similarity.cosine($embedding, e.embedding ) <= 0.95\\nTHEN \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,1}(:!Chunk&!Document) RETURN path }\\nELSE \\ncollect { OPTIONAL MATCH path=(e)(()-[rels:!HAS_ENTITY&!PART_OF]-()){0,2}(:!Chunk&!Document) RETURN path } \\nEND as paths, e\\nWITH apoc.coll.toSet(apoc.coll.flatten(collect(distinct paths))) as paths, collect(distinct e) as entities\\n// de-duplicate nodes and relationships across chunks\\nRETURN collect{ unwind paths as p unwind relationships(p) as r return distinct r} as rels,\\ncollect{ unwind paths as p unwind nodes(p) as n return distinct n} as nodes, entities\\n}\\n\\n// generate metadata and text components for chunks, nodes and relationships\\nWITH d, avg_score,\\n     [c IN chunks | c.chunk.text] AS texts, \\n     [c IN chunks | {id: c.chunk.id, score: c.score}] AS chunkdetails, \\n  apoc.coll.sort([n in nodes | \\n\\ncoalesce(apoc.coll.removeAll(labels(n),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nn.id + (case when n.description is not null then \" (\"+ n.description+\")\" else \"\" end)]) as nodeTexts,\\n\\tapoc.coll.sort([r in rels \\n    // optional filter if we limit the node-set\\n    // WHERE startNode(r) in nodes AND endNode(r) in nodes \\n  | \\ncoalesce(apoc.coll.removeAll(labels(startNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\"+ \\nstartNode(r).id +\\n\" \" + type(r) + \" \" + \\ncoalesce(apoc.coll.removeAll(labels(endNode(r)),[\\'__Entity__\\'])[0],\"\") +\":\" + endNode(r).id\\n]) as relTexts\\n, entities\\n// combine texts into response-text\\n\\nWITH d, avg_score,chunkdetails,\\n\"Text Content:\\\\n\" +\\napoc.text.join(texts,\"\\\\n----\\\\n\") +\\n\"\\\\n----\\\\nEntities:\\\\n\"+\\napoc.text.join(nodeTexts,\"\\\\n\") +\\n\"\\\\n----\\\\nRelationships:\\\\n\" +\\napoc.text.join(relTexts,\"\\\\n\")\\n\\nas text,entities\\n\\nRETURN text, avg_score as score, {length:size(text), source: COALESCE( CASE WHEN d.url CONTAINS \"None\" THEN d.fileName ELSE d.url END, d.fileName), chunkdetails: chunkdetails} AS metadata\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What happens when there is not enough oxygen to the brain?\n",
      "Without a steady supply of oxygen, the nervous tissue in the brain cannot keep up its extensive electrical activity. \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9453dfcb8fe647698dc22360c07ebe80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now create loads of questions and answers and get RAG metrics\n",
    "\n",
    "# Question - Answer Ground Truth Pairs with reference\n",
    "qa_df = pd.read_csv(\"graphrag_qa_groundtruth.csv\")\n",
    "\n",
    "# Initialize EvaluationDataset()\n",
    "ragas_sample_list = []\n",
    "\n",
    "llm,model_name = get_llm(model)\n",
    "\n",
    "# Hybrid Cypher\n",
    "mode =\"graph + vector + fulltext\"\n",
    "\n",
    "# under QA_RAG with Hybrid Search\n",
    "retrieval_query = VECTOR_GRAPH_SEARCH_QUERY.format(no_of_entites=VECTOR_GRAPH_SEARCH_ENTITY_LIMIT)\n",
    "\n",
    "# Create retriever\n",
    "index_name = \"vector\"\n",
    "keyword_index = \"keyword\"\n",
    "\n",
    "retriever = HybridCypherRetriever(\n",
    "    driver=driver,\n",
    "    vector_index_name=index_name,\n",
    "    fulltext_index_name=keyword_index,\n",
    "    retrieval_query=retrieval_query,\n",
    "    embedder=EMBEDDING_FUNCTION,\n",
    ")\n",
    "\n",
    "llm = VertexAILLM(model_name=\"gemini-1.5-flash-001\")\n",
    "rag = GraphRAG(retriever=retriever, llm=llm)\n",
    "\n",
    "# Iterate through all questions and answers (ground truth)\n",
    "for index, row in qa_df.iterrows():\n",
    "    retriever_result = retriever.search(query_text=row[\"question\"], top_k=4)\n",
    "    hybridcypher_response = rag.search(query_text=row[\"question\"],retriever_config={\"top_k\":4})\n",
    "    hybridcypher_chunkdetails = []\n",
    "    for m in retriever_result.items:\n",
    "        hybridcypher_chunkdetails.append(m.metadata[\"chunkdetails\"])\n",
    "    \n",
    "    retrieved_contexts = []\n",
    "    # getChunkDetails\n",
    "    for fileName,context,score,id in getChunkDetails(hybridcypher_chunkdetails[0]):\n",
    "        retrieved_contexts.append(context)\n",
    "    \n",
    "    # Create RAGAS SingleTurnSample\n",
    "    sample= SingleTurnSample(\n",
    "        user_input=str(row[\"question\"]),\n",
    "        retrieved_contexts=retrieved_contexts,\n",
    "        reference_contexts=[row[\"reference_contexts\"]],\n",
    "        response=hybridcypher_response.answer,\n",
    "        reference=str(row[\"reference_answer\"]),\n",
    "        rubric=rubric\n",
    "    )\n",
    "    print(row[\"question\"])\n",
    "    print(hybridcypher_response.answer)\n",
    "    ragas_sample_list.append(sample)\n",
    "    \n",
    "\n",
    "ds = EvaluationDataset(ragas_sample_list)\n",
    "result = evaluate(\n",
    "    dataset=ds,\n",
    "    metrics = metrics\n",
    ")\n",
    "result = result.to_pandas()\n",
    "result[\"retrieval_type\"] = \"hybridCypher\"\n",
    "df = pd.concat([df,result], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>response</th>\n",
       "      <th>retrieval_type</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How is the pia mater connected with the central nervous system?</td>\n",
       "      <td>The pia mater is directly adjacent to the surface of the central nervous system (CNS). It's a thin fibrous membrane that closely follows the convolutions of the gyri and sulci in the cerebral cortex, as well as other grooves and indentations. This close adherence means the pia mater essentially envelops the CNS, providing a delicate and protective covering. \\n</td>\n",
       "      <td>hybrid(v+keyword)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920533</td>\n",
       "      <td>0.970918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How is the pia mater connected with the central nervous system?</td>\n",
       "      <td>The pia mater is a thin fibrous membrane that directly adjoins the surface of the CNS. It follows the convolutions of the gyri and sulci in the cerebral cortex and fits into other grooves and indentations.  \\n</td>\n",
       "      <td>hybridCypher</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971699</td>\n",
       "      <td>0.957396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How is the pia mater connected with the central nervous system?</td>\n",
       "      <td>The pia mater is a thin, delicate membrane that directly adheres to the surface of the central nervous system (CNS). It's like a thin, protective layer that follows the contours of the brain and spinal cord, extending into every convolution and groove. This close connection allows the pia mater to provide a gentle covering and support for the delicate tissues of the CNS. \\n</td>\n",
       "      <td>vector</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.835625</td>\n",
       "      <td>0.945187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How many ventricles exist and how are they connected?</td>\n",
       "      <td>There are four ventricles within the brain: two lateral ventricles, the third ventricle, and the fourth ventricle. \\n\\n* The **lateral ventricles** are located deep within the cerebrum and are connected to the **third ventricle** by two openings called the **interventricular foramina**. \\n* The **third ventricle** is situated between the left and right sides of the diencephalon and opens into the **cerebral aqueduct**, which passes through the midbrain. \\n* The **cerebral aqueduct** then opens into the **fourth ventricle**, which is located between the cerebellum and the pons and upper medulla. \\n</td>\n",
       "      <td>hybrid(v+keyword)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.585312</td>\n",
       "      <td>0.924431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>How many ventricles exist and how are they connected?</td>\n",
       "      <td>There are four ventricles within the brain:\\n\\n* **Two lateral ventricles:** These are deep within the cerebrum and are connected to the third ventricle by two openings called the interventricular foramina.\\n* **Third ventricle:** This is the space between the left and right sides of the diencephalon and opens into the cerebral aqueduct.\\n* **Cerebral aqueduct:** This passage connects the third ventricle to the fourth ventricle through the midbrain.\\n* **Fourth ventricle:** This is the space between the cerebellum and the pons and upper medulla. \\n</td>\n",
       "      <td>hybridCypher</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.778360</td>\n",
       "      <td>0.924983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How many ventricles exist and how are they connected?</td>\n",
       "      <td>There are four ventricles in the brain: two lateral ventricles, the third ventricle, and the fourth ventricle. \\n\\n* The **lateral ventricles** are located deep within the cerebrum and are connected to the **third ventricle** by two openings called the **interventricular foramina**. \\n* The **third ventricle** is situated between the left and right sides of the diencephalon and opens into the **cerebral aqueduct**, which passes through the midbrain. \\n* The **cerebral aqueduct** then opens into the **fourth ventricle**, which is located between the cerebellum and the pons and upper medulla. \\n</td>\n",
       "      <td>vector</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.614052</td>\n",
       "      <td>0.924931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are all the arteries in the Circle of Willis?</td>\n",
       "      <td>The Circle of Willis is a ring-shaped structure of arteries at the base of the brain. It is formed by the following arteries:\\n\\n* **Internal carotid arteries:** These arteries enter the skull through the carotid canal and branch into the anterior cerebral artery and the middle cerebral artery.\\n* **Anterior cerebral arteries:** These arteries supply blood to the frontal lobes and parts of the parietal lobes.\\n* **Middle cerebral arteries:** These arteries supply blood to the lateral surfaces of the cerebral hemispheres.\\n* **Posterior cerebral arteries:** These arteries supply blood to the occipital lobes and parts of the temporal lobes.\\n* **Posterior communicating arteries:** These arteries connect the internal carotid arteries to the posterior cerebral arteries.\\n* **Anterior communicating artery:** This artery connects the two anterior cerebral arteries.\\n* **Basilar artery:** This artery is formed by the merging of the two vertebral arteries and gives rise to branches to the brainstem and cerebellum. \\n</td>\n",
       "      <td>hybrid(v+keyword)</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.912069</td>\n",
       "      <td>0.923813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What are all the arteries in the Circle of Willis?</td>\n",
       "      <td>The Circle of Willis is formed by the confluence of the following arteries: \\n\\n* **Internal carotid arteries:** These arteries enter the cranium through the carotid canal and contribute to the circle. \\n* **Vertebral arteries:** These arteries pass through the neck region and enter the cranium through the foramen magnum. They merge to form the basilar artery.\\n* **Basilar artery:** This artery is formed by the merging of the two vertebral arteries. It gives rise to branches to the brainstem and cerebellum and contributes to the Circle of Willis. \\n</td>\n",
       "      <td>hybridCypher</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0.951883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are all the arteries in the Circle of Willis?</td>\n",
       "      <td>The Circle of Willis is a ring-shaped structure of arteries at the base of the brain. It is formed by the following arteries:\\n\\n* **Internal carotid arteries:** These arteries branch from the common carotid arteries and enter the skull through the carotid canal.\\n* **Anterior cerebral arteries:** These arteries arise from the internal carotid arteries and supply the medial and anterior portions of the frontal and parietal lobes.\\n* **Anterior communicating artery:** This small artery connects the two anterior cerebral arteries.\\n* **Posterior cerebral arteries:** These arteries arise from the basilar artery and supply the posterior portions of the brain, including the occipital lobes and the temporal lobes.\\n* **Posterior communicating arteries:** These arteries connect the internal carotid arteries to the posterior cerebral arteries.\\n* **Basilar artery:** This artery is formed by the union of the two vertebral arteries and supplies the brainstem and cerebellum. \\n</td>\n",
       "      <td>vector</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.734602</td>\n",
       "      <td>0.923813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What happens when there is not enough oxygen to the brain?</td>\n",
       "      <td>When there is not enough oxygen to the brain, it can lead to a condition called **hypoxia**. This can cause a range of problems, from mild cognitive impairment to severe brain damage and even death. \\n\\nThe brain requires a constant supply of oxygen to function properly. Without oxygen, brain cells begin to die. The severity of the damage depends on how long the brain is deprived of oxygen. \\n\\nHere are some of the effects of hypoxia:\\n\\n* **Confusion and disorientation:**  The brain may not be able to process information correctly, leading to confusion and difficulty thinking clearly.\\n* **Dizziness and headaches:**  These symptoms can occur due to the brain's inability to function properly.\\n* **Seizures:**  In severe cases, hypoxia can trigger seizures.\\n* **Coma:**  If the brain is deprived of oxygen for a long time, it can lead to a coma.\\n* **Brain damage:**  Prolonged hypoxia can cause permanent brain damage, leading to long-term disabilities.\\n\\nIt's important to note that the effects of hypoxia can vary depending on the individual and the severity of the oxygen deprivation. \\n</td>\n",
       "      <td>hybrid(v+keyword)</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.964350</td>\n",
       "      <td>0.909997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What happens when there is not enough oxygen to the brain?</td>\n",
       "      <td>Without a steady supply of oxygen, the nervous tissue in the brain cannot keep up its extensive electrical activity. \\n</td>\n",
       "      <td>hybridCypher</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.742866</td>\n",
       "      <td>0.919314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What happens when there is not enough oxygen to the brain?</td>\n",
       "      <td>When there is not enough oxygen to the brain, it can lead to a condition called **hypoxia**. This can cause a range of problems, from mild cognitive impairment to severe brain damage and even death. \\n\\nThe brain requires a constant supply of oxygen to function properly. Without oxygen, brain cells cannot produce energy and begin to die. The severity of the damage depends on how long the brain is deprived of oxygen. \\n\\nSome symptoms of hypoxia include:\\n\\n* Dizziness\\n* Confusion\\n* Headache\\n* Seizures\\n* Loss of consciousness\\n\\nIf you suspect someone is experiencing hypoxia, it is important to seek medical attention immediately. \\n</td>\n",
       "      <td>vector</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.778861</td>\n",
       "      <td>0.974463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the Circle of Willis?</td>\n",
       "      <td>The Circle of Willis is a specialized arrangement of arteries at the base of the brain that ensures constant blood flow to the cerebrum, even if there is a blockage in one of the arteries. It's a confluence of arteries that can maintain perfusion of the brain even if narrowing or a blockage limits flow through one part. \\n</td>\n",
       "      <td>hybrid(v+keyword)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990704</td>\n",
       "      <td>0.957592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What is the Circle of Willis?</td>\n",
       "      <td>The Circle of Willis is a confluence of arteries that can maintain perfusion of the brain even if narrowing or a blockage limits flow through one part. \\n</td>\n",
       "      <td>hybridCypher</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.487950</td>\n",
       "      <td>0.988185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the Circle of Willis?</td>\n",
       "      <td>I'm sorry, but the provided context does not contain information about the Circle of Willis. \\n</td>\n",
       "      <td>vector</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207249</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Why is there a barrier between the central nervous system and the blood supply?</td>\n",
       "      <td>The barrier between the central nervous system (CNS) and the blood supply, known as the blood-brain barrier, exists to protect the delicate brain and spinal cord from harmful substances in the bloodstream. This barrier is crucial because the CNS is highly sensitive to toxins, pathogens, and fluctuations in blood composition. \\n\\nThe blood-brain barrier acts as a selective filter, allowing essential nutrients and oxygen to pass through while blocking potentially harmful substances. This protection ensures the optimal functioning of the CNS and prevents damage that could lead to neurological disorders. \\n</td>\n",
       "      <td>hybrid(v+keyword)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223371</td>\n",
       "      <td>0.884911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Why is there a barrier between the central nervous system and the blood supply?</td>\n",
       "      <td>The blood-brain barrier exists to protect the central nervous system (CNS) from harmful substances that might be circulating in the bloodstream. This barrier is critical because the CNS is highly sensitive and vulnerable to toxins, pathogens, and other potentially damaging elements. \\n</td>\n",
       "      <td>hybridCypher</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.723136</td>\n",
       "      <td>0.886782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why is there a barrier between the central nervous system and the blood supply?</td>\n",
       "      <td>The barrier between the central nervous system (CNS) and the blood supply, known as the blood-brain barrier, exists to protect the delicate brain and spinal cord from harmful substances in the bloodstream. This barrier is crucial because the CNS is highly sensitive to toxins, pathogens, and fluctuations in blood composition. \\n\\nThe blood-brain barrier acts as a selective filter, allowing essential nutrients and oxygen to pass through while blocking potentially harmful substances. This protection ensures the optimal functioning of the CNS and prevents damage that could lead to neurological disorders. \\n</td>\n",
       "      <td>vector</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.223371</td>\n",
       "      <td>0.886798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         user_input  \\\n",
       "9                   How is the pia mater connected with the central nervous system?   \n",
       "15                  How is the pia mater connected with the central nervous system?   \n",
       "3                   How is the pia mater connected with the central nervous system?   \n",
       "10                            How many ventricles exist and how are they connected?   \n",
       "16                            How many ventricles exist and how are they connected?   \n",
       "4                             How many ventricles exist and how are they connected?   \n",
       "7                                What are all the arteries in the Circle of Willis?   \n",
       "13                               What are all the arteries in the Circle of Willis?   \n",
       "1                                What are all the arteries in the Circle of Willis?   \n",
       "11                       What happens when there is not enough oxygen to the brain?   \n",
       "17                       What happens when there is not enough oxygen to the brain?   \n",
       "5                        What happens when there is not enough oxygen to the brain?   \n",
       "6                                                     What is the Circle of Willis?   \n",
       "12                                                    What is the Circle of Willis?   \n",
       "0                                                     What is the Circle of Willis?   \n",
       "8   Why is there a barrier between the central nervous system and the blood supply?   \n",
       "14  Why is there a barrier between the central nervous system and the blood supply?   \n",
       "2   Why is there a barrier between the central nervous system and the blood supply?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          response  \\\n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       The pia mater is directly adjacent to the surface of the central nervous system (CNS). It's a thin fibrous membrane that closely follows the convolutions of the gyri and sulci in the cerebral cortex, as well as other grooves and indentations. This close adherence means the pia mater essentially envelops the CNS, providing a delicate and protective covering. \\n   \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               The pia mater is a thin fibrous membrane that directly adjoins the surface of the CNS. It follows the convolutions of the gyri and sulci in the cerebral cortex and fits into other grooves and indentations.  \\n   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         The pia mater is a thin, delicate membrane that directly adheres to the surface of the central nervous system (CNS). It's like a thin, protective layer that follows the contours of the brain and spinal cord, extending into every convolution and groove. This close connection allows the pia mater to provide a gentle covering and support for the delicate tissues of the CNS. \\n   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    There are four ventricles within the brain: two lateral ventricles, the third ventricle, and the fourth ventricle. \\n\\n* The **lateral ventricles** are located deep within the cerebrum and are connected to the **third ventricle** by two openings called the **interventricular foramina**. \\n* The **third ventricle** is situated between the left and right sides of the diencephalon and opens into the **cerebral aqueduct**, which passes through the midbrain. \\n* The **cerebral aqueduct** then opens into the **fourth ventricle**, which is located between the cerebellum and the pons and upper medulla. \\n   \n",
       "16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      There are four ventricles within the brain:\\n\\n* **Two lateral ventricles:** These are deep within the cerebrum and are connected to the third ventricle by two openings called the interventricular foramina.\\n* **Third ventricle:** This is the space between the left and right sides of the diencephalon and opens into the cerebral aqueduct.\\n* **Cerebral aqueduct:** This passage connects the third ventricle to the fourth ventricle through the midbrain.\\n* **Fourth ventricle:** This is the space between the cerebellum and the pons and upper medulla. \\n   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         There are four ventricles in the brain: two lateral ventricles, the third ventricle, and the fourth ventricle. \\n\\n* The **lateral ventricles** are located deep within the cerebrum and are connected to the **third ventricle** by two openings called the **interventricular foramina**. \\n* The **third ventricle** is situated between the left and right sides of the diencephalon and opens into the **cerebral aqueduct**, which passes through the midbrain. \\n* The **cerebral aqueduct** then opens into the **fourth ventricle**, which is located between the cerebellum and the pons and upper medulla. \\n   \n",
       "7                                                                                 The Circle of Willis is a ring-shaped structure of arteries at the base of the brain. It is formed by the following arteries:\\n\\n* **Internal carotid arteries:** These arteries enter the skull through the carotid canal and branch into the anterior cerebral artery and the middle cerebral artery.\\n* **Anterior cerebral arteries:** These arteries supply blood to the frontal lobes and parts of the parietal lobes.\\n* **Middle cerebral arteries:** These arteries supply blood to the lateral surfaces of the cerebral hemispheres.\\n* **Posterior cerebral arteries:** These arteries supply blood to the occipital lobes and parts of the temporal lobes.\\n* **Posterior communicating arteries:** These arteries connect the internal carotid arteries to the posterior cerebral arteries.\\n* **Anterior communicating artery:** This artery connects the two anterior cerebral arteries.\\n* **Basilar artery:** This artery is formed by the merging of the two vertebral arteries and gives rise to branches to the brainstem and cerebellum. \\n   \n",
       "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     The Circle of Willis is formed by the confluence of the following arteries: \\n\\n* **Internal carotid arteries:** These arteries enter the cranium through the carotid canal and contribute to the circle. \\n* **Vertebral arteries:** These arteries pass through the neck region and enter the cranium through the foramen magnum. They merge to form the basilar artery.\\n* **Basilar artery:** This artery is formed by the merging of the two vertebral arteries. It gives rise to branches to the brainstem and cerebellum and contributes to the Circle of Willis. \\n   \n",
       "1                                                                                                                            The Circle of Willis is a ring-shaped structure of arteries at the base of the brain. It is formed by the following arteries:\\n\\n* **Internal carotid arteries:** These arteries branch from the common carotid arteries and enter the skull through the carotid canal.\\n* **Anterior cerebral arteries:** These arteries arise from the internal carotid arteries and supply the medial and anterior portions of the frontal and parietal lobes.\\n* **Anterior communicating artery:** This small artery connects the two anterior cerebral arteries.\\n* **Posterior cerebral arteries:** These arteries arise from the basilar artery and supply the posterior portions of the brain, including the occipital lobes and the temporal lobes.\\n* **Posterior communicating arteries:** These arteries connect the internal carotid arteries to the posterior cerebral arteries.\\n* **Basilar artery:** This artery is formed by the union of the two vertebral arteries and supplies the brainstem and cerebellum. \\n   \n",
       "11  When there is not enough oxygen to the brain, it can lead to a condition called **hypoxia**. This can cause a range of problems, from mild cognitive impairment to severe brain damage and even death. \\n\\nThe brain requires a constant supply of oxygen to function properly. Without oxygen, brain cells begin to die. The severity of the damage depends on how long the brain is deprived of oxygen. \\n\\nHere are some of the effects of hypoxia:\\n\\n* **Confusion and disorientation:**  The brain may not be able to process information correctly, leading to confusion and difficulty thinking clearly.\\n* **Dizziness and headaches:**  These symptoms can occur due to the brain's inability to function properly.\\n* **Seizures:**  In severe cases, hypoxia can trigger seizures.\\n* **Coma:**  If the brain is deprived of oxygen for a long time, it can lead to a coma.\\n* **Brain damage:**  Prolonged hypoxia can cause permanent brain damage, leading to long-term disabilities.\\n\\nIt's important to note that the effects of hypoxia can vary depending on the individual and the severity of the oxygen deprivation. \\n   \n",
       "17                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Without a steady supply of oxygen, the nervous tissue in the brain cannot keep up its extensive electrical activity. \\n   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                              When there is not enough oxygen to the brain, it can lead to a condition called **hypoxia**. This can cause a range of problems, from mild cognitive impairment to severe brain damage and even death. \\n\\nThe brain requires a constant supply of oxygen to function properly. Without oxygen, brain cells cannot produce energy and begin to die. The severity of the damage depends on how long the brain is deprived of oxygen. \\n\\nSome symptoms of hypoxia include:\\n\\n* Dizziness\\n* Confusion\\n* Headache\\n* Seizures\\n* Loss of consciousness\\n\\nIf you suspect someone is experiencing hypoxia, it is important to seek medical attention immediately. \\n   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             The Circle of Willis is a specialized arrangement of arteries at the base of the brain that ensures constant blood flow to the cerebrum, even if there is a blockage in one of the arteries. It's a confluence of arteries that can maintain perfusion of the brain even if narrowing or a blockage limits flow through one part. \\n   \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      The Circle of Willis is a confluence of arteries that can maintain perfusion of the brain even if narrowing or a blockage limits flow through one part. \\n   \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  I'm sorry, but the provided context does not contain information about the Circle of Willis. \\n   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               The barrier between the central nervous system (CNS) and the blood supply, known as the blood-brain barrier, exists to protect the delicate brain and spinal cord from harmful substances in the bloodstream. This barrier is crucial because the CNS is highly sensitive to toxins, pathogens, and fluctuations in blood composition. \\n\\nThe blood-brain barrier acts as a selective filter, allowing essential nutrients and oxygen to pass through while blocking potentially harmful substances. This protection ensures the optimal functioning of the CNS and prevents damage that could lead to neurological disorders. \\n   \n",
       "14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  The blood-brain barrier exists to protect the central nervous system (CNS) from harmful substances that might be circulating in the bloodstream. This barrier is critical because the CNS is highly sensitive and vulnerable to toxins, pathogens, and other potentially damaging elements. \\n   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               The barrier between the central nervous system (CNS) and the blood supply, known as the blood-brain barrier, exists to protect the delicate brain and spinal cord from harmful substances in the bloodstream. This barrier is crucial because the CNS is highly sensitive to toxins, pathogens, and fluctuations in blood composition. \\n\\nThe blood-brain barrier acts as a selective filter, allowing essential nutrients and oxygen to pass through while blocking potentially harmful substances. This protection ensures the optimal functioning of the CNS and prevents damage that could lead to neurological disorders. \\n   \n",
       "\n",
       "       retrieval_type  faithfulness  answer_correctness  answer_relevancy  \n",
       "9   hybrid(v+keyword)      1.000000            0.920533          0.970918  \n",
       "15       hybridCypher      1.000000            0.971699          0.957396  \n",
       "3              vector      0.714286            0.835625          0.945187  \n",
       "10  hybrid(v+keyword)      1.000000            0.585312          0.924431  \n",
       "16       hybridCypher      1.000000            0.778360          0.924983  \n",
       "4              vector      1.000000            0.614052          0.924931  \n",
       "7   hybrid(v+keyword)      0.400000            0.912069          0.923813  \n",
       "13       hybridCypher      0.888889            0.564516          0.951883  \n",
       "1              vector      0.428571            0.734602          0.923813  \n",
       "11  hybrid(v+keyword)      0.733333            0.964350          0.909997  \n",
       "17       hybridCypher      1.000000            0.742866          0.919314  \n",
       "5              vector      1.000000            0.778861          0.974463  \n",
       "6   hybrid(v+keyword)      1.000000            0.990704          0.957592  \n",
       "12       hybridCypher      1.000000            0.487950          0.988185  \n",
       "0              vector      1.000000            0.207249          0.000000  \n",
       "8   hybrid(v+keyword)      1.000000            0.223371          0.884911  \n",
       "14       hybridCypher      0.750000            0.723136          0.886782  \n",
       "2              vector      0.750000            0.223371          0.886798  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final Dataframe\n",
    "desired_col = ['semantic_similarity','faithfulness','answer_correctness','answer_relevancy','retrieval_type']\n",
    "df[desired_col]\n",
    "pd.set_option('display.max_colwidth',None)\n",
    "df[['user_input','response','retrieval_type','faithfulness','answer_correctness','answer_relevancy']].sort_values(by=['user_input','retrieval_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrieval_type</th>\n",
       "      <th>avg_semantic_similarity</th>\n",
       "      <th>avg_faithfulness</th>\n",
       "      <th>avg_correctness</th>\n",
       "      <th>avg_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vector</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hybrid(v+keyword)</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hybridCypher</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      retrieval_type  avg_semantic_similarity  avg_faithfulness  \\\n",
       "0             vector                    0.878             0.815   \n",
       "1  hybrid(v+keyword)                    0.900             0.856   \n",
       "2       hybridCypher                    0.924             0.940   \n",
       "\n",
       "   avg_correctness  avg_relevancy  \n",
       "0            0.566          0.776  \n",
       "1            0.766          0.929  \n",
       "2            0.711          0.938  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Calculate the average semantic similarity and faithfulness based on retrieval_type\n",
    "average_metrics = df.groupby('retrieval_type').agg({\n",
    "    'semantic_similarity': 'mean',\n",
    "    'faithfulness': 'mean',\n",
    "    'answer_correctness':'mean',\n",
    "    'answer_relevancy':'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "average_metrics.columns = ['retrieval_type', 'avg_semantic_similarity', 'avg_faithfulness','avg_correctness','avg_relevancy']\n",
    "\n",
    "# Define the custom order\n",
    "custom_order = ['vector', 'hybrid(v+keyword)', 'hybridCypher']\n",
    "\n",
    "# Create a categorical type with the custom order\n",
    "average_metrics['retrieval_type'] = pd.Categorical(average_metrics['retrieval_type'], categories=custom_order, ordered=True)\n",
    "\n",
    "# Sort the DataFrame by the custom order\n",
    "average_metrics_sorted = average_metrics.sort_values(by='retrieval_type').reset_index(drop=True)\n",
    "\n",
    "# Round each numeric value to 3 decimal places\n",
    "average_metrics_sorted.iloc[:, 1:] = average_metrics_sorted.iloc[:, 1:].round(3)\n",
    "\n",
    "# Display the sorted and rounded DataFrame\n",
    "average_metrics_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>retrieval_type=vector<br>answer_correctness=%{x}<br>faithfulness=%{y}<extra></extra>",
         "hovertext": [
          0,
          1,
          2,
          3,
          4,
          5
         ],
         "legendgroup": "vector",
         "marker": {
          "color": "rgb(228,26,28)",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "vector",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0.2072494617813087,
          0.7346020508010879,
          0.22337143641399465,
          0.8356254534742239,
          0.6140523442665428,
          0.778860747047464
         ],
         "xaxis": "x",
         "y": [
          1,
          0.42857142857142855,
          0.75,
          0.7142857142857143,
          1,
          1
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>retrieval_type=hybrid(v+keyword)<br>answer_correctness=%{x}<br>faithfulness=%{y}<extra></extra>",
         "hovertext": [
          6,
          7,
          8,
          9,
          10,
          11
         ],
         "legendgroup": "hybrid(v+keyword)",
         "marker": {
          "color": "rgb(55,126,184)",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "hybrid(v+keyword)",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0.9907038715705387,
          0.9120692266334097,
          0.22337143641399465,
          0.9205332978603549,
          0.5853120750241488,
          0.9643498831733837
         ],
         "xaxis": "x",
         "y": [
          1,
          0.4,
          1,
          1,
          1,
          0.7333333333333333
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>retrieval_type=hybridCypher<br>answer_correctness=%{x}<br>faithfulness=%{y}<extra></extra>",
         "hovertext": [
          12,
          13,
          14,
          15,
          16,
          17
         ],
         "legendgroup": "hybridCypher",
         "marker": {
          "color": "rgb(77,175,74)",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "hybridCypher",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0.48795017348865505,
          0.5645158670009264,
          0.7231363855153572,
          0.9716994679147233,
          0.7783603308486515,
          0.7428662754025529
         ],
         "xaxis": "x",
         "y": [
          1,
          0.8888888888888888,
          0.75,
          1,
          1,
          1
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>retrieval_type=vector<br>answer_correctness=%{x}<br>answer_relevancy=%{y}<extra></extra>",
         "hovertext": [
          0,
          1,
          2,
          3,
          4,
          5
         ],
         "legendgroup": "vector",
         "marker": {
          "color": "rgb(228,26,28)",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "vector",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.2072494617813087,
          0.7346020508010879,
          0.22337143641399465,
          0.8356254534742239,
          0.6140523442665428,
          0.778860747047464
         ],
         "xaxis": "x2",
         "y": [
          0,
          0.9238130591239125,
          0.8867981301996061,
          0.9451873196684596,
          0.9249306026297686,
          0.9744631785512645
         ],
         "yaxis": "y2"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>retrieval_type=hybrid(v+keyword)<br>answer_correctness=%{x}<br>answer_relevancy=%{y}<extra></extra>",
         "hovertext": [
          6,
          7,
          8,
          9,
          10,
          11
         ],
         "legendgroup": "hybrid(v+keyword)",
         "marker": {
          "color": "rgb(55,126,184)",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "hybrid(v+keyword)",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.9907038715705387,
          0.9120692266334097,
          0.22337143641399465,
          0.9205332978603549,
          0.5853120750241488,
          0.9643498831733837
         ],
         "xaxis": "x2",
         "y": [
          0.957592305115983,
          0.9238130591239125,
          0.8849110843705504,
          0.9709179493923635,
          0.9244307219767314,
          0.9099965990677777
         ],
         "yaxis": "y2"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>retrieval_type=hybridCypher<br>answer_correctness=%{x}<br>answer_relevancy=%{y}<extra></extra>",
         "hovertext": [
          12,
          13,
          14,
          15,
          16,
          17
         ],
         "legendgroup": "hybridCypher",
         "marker": {
          "color": "rgb(77,175,74)",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "hybridCypher",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.48795017348865505,
          0.5645158670009264,
          0.7231363855153572,
          0.9716994679147233,
          0.7783603308486515,
          0.7428662754025529
         ],
         "xaxis": "x2",
         "y": [
          0.9881852598800798,
          0.9518827609949018,
          0.8867817027027979,
          0.9573957482470595,
          0.9249832036648963,
          0.919313566373292
         ],
         "yaxis": "y2"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>retrieval_type=vector<br>semantic_similarity=%{x}<br>faithfulness=%{y}<extra></extra>",
         "hovertext": [
          0,
          1,
          2,
          3,
          4,
          5
         ],
         "legendgroup": "vector",
         "marker": {
          "color": "rgb(228,26,28)",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "vector",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.8289978471252348,
          0.8514516814652212,
          0.8934857456559786,
          0.8719135786027779,
          0.9562108458492682,
          0.8654429881898565
         ],
         "xaxis": "x3",
         "y": [
          1,
          0.42857142857142855,
          0.75,
          0.7142857142857143,
          1,
          1
         ],
         "yaxis": "y3"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>retrieval_type=hybrid(v+keyword)<br>semantic_similarity=%{x}<br>faithfulness=%{y}<extra></extra>",
         "hovertext": [
          6,
          7,
          8,
          9,
          10,
          11
         ],
         "legendgroup": "hybrid(v+keyword)",
         "marker": {
          "color": "rgb(55,126,184)",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "hybrid(v+keyword)",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.962815486282155,
          0.8482769065336391,
          0.8934857456559786,
          0.8821331914414194,
          0.9566329154812108,
          0.8573995326935349
         ],
         "xaxis": "x3",
         "y": [
          1,
          0.4,
          1,
          1,
          1,
          0.7333333333333333
         ],
         "yaxis": "y3"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>retrieval_type=hybridCypher<br>semantic_similarity=%{x}<br>faithfulness=%{y}<extra></extra>",
         "hovertext": [
          12,
          13,
          14,
          15,
          16,
          17
         ],
         "legendgroup": "hybridCypher",
         "marker": {
          "color": "rgb(77,175,74)",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "hybridCypher",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.9518006939546202,
          0.873448083388321,
          0.8925455420614289,
          0.8867978716588931,
          0.9706004881023642,
          0.9714651016102116
         ],
         "xaxis": "x3",
         "y": [
          1,
          0.8888888888888888,
          0.75,
          1,
          1,
          1
         ],
         "yaxis": "y3"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>retrieval_type=vector<br>semantic_similarity=%{x}<br>answer_correctness=%{y}<extra></extra>",
         "hovertext": [
          0,
          1,
          2,
          3,
          4,
          5
         ],
         "legendgroup": "vector",
         "marker": {
          "color": "rgb(228,26,28)",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "vector",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.8289978471252348,
          0.8514516814652212,
          0.8934857456559786,
          0.8719135786027779,
          0.9562108458492682,
          0.8654429881898565
         ],
         "xaxis": "x4",
         "y": [
          0.2072494617813087,
          0.7346020508010879,
          0.22337143641399465,
          0.8356254534742239,
          0.6140523442665428,
          0.778860747047464
         ],
         "yaxis": "y4"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>retrieval_type=hybrid(v+keyword)<br>semantic_similarity=%{x}<br>answer_correctness=%{y}<extra></extra>",
         "hovertext": [
          6,
          7,
          8,
          9,
          10,
          11
         ],
         "legendgroup": "hybrid(v+keyword)",
         "marker": {
          "color": "rgb(55,126,184)",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "hybrid(v+keyword)",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.962815486282155,
          0.8482769065336391,
          0.8934857456559786,
          0.8821331914414194,
          0.9566329154812108,
          0.8573995326935349
         ],
         "xaxis": "x4",
         "y": [
          0.9907038715705387,
          0.9120692266334097,
          0.22337143641399465,
          0.9205332978603549,
          0.5853120750241488,
          0.9643498831733837
         ],
         "yaxis": "y4"
        },
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>retrieval_type=hybridCypher<br>semantic_similarity=%{x}<br>answer_correctness=%{y}<extra></extra>",
         "hovertext": [
          12,
          13,
          14,
          15,
          16,
          17
         ],
         "legendgroup": "hybridCypher",
         "marker": {
          "color": "rgb(77,175,74)",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "hybridCypher",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.9518006939546202,
          0.873448083388321,
          0.8925455420614289,
          0.8867978716588931,
          0.9706004881023642,
          0.9714651016102116
         ],
         "xaxis": "x4",
         "y": [
          0.48795017348865505,
          0.5645158670009264,
          0.7231363855153572,
          0.9716994679147233,
          0.7783603308486515,
          0.7428662754025529
         ],
         "yaxis": "y4"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Faithfulness vs Correctness",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Relevancy vs Correctness",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Faithfulness vs Semantic Similarity",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Correctness vs Semantic Similarity",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 800,
        "legend": {
         "orientation": "h",
         "x": 0.5,
         "xanchor": "center",
         "y": 0.475,
         "yanchor": "bottom"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "GraphRAG w/ RAGAS Metrics"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "dtick": 0.1,
         "gridwidth": 1,
         "range": [
          0,
          1.05
         ],
         "title": {
          "text": "Correctness"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "dtick": 0.1,
         "gridwidth": 1,
         "range": [
          0,
          1.05
         ],
         "title": {
          "text": "Correctness"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.45
         ],
         "dtick": 0.1,
         "gridwidth": 1,
         "range": [
          0,
          1.05
         ],
         "title": {
          "text": "Semantic similarity"
         }
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.55,
          1
         ],
         "dtick": 0.1,
         "gridwidth": 1,
         "range": [
          0,
          1.05
         ],
         "title": {
          "text": "Semantic similarity"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.625,
          1
         ],
         "dtick": 0.1,
         "gridwidth": 1,
         "range": [
          0,
          1.05
         ],
         "title": {
          "text": "Faithfulness"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.625,
          1
         ],
         "dtick": 0.1,
         "gridwidth": 1,
         "range": [
          0,
          1.05
         ],
         "title": {
          "text": "Relevancy"
         }
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          0.375
         ],
         "dtick": 0.1,
         "gridwidth": 1,
         "range": [
          0,
          1.05
         ],
         "title": {
          "text": "Faithfulness"
         }
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          0.375
         ],
         "dtick": 0.1,
         "gridwidth": 1,
         "range": [
          0,
          1.05
         ],
         "title": {
          "text": "Correctness"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "desired_col = ['semantic_similarity','faithfulness','answer_correctness','answer_relevancy','retrieval_type']\n",
    "\n",
    "# Create a subplot grid\n",
    "fig = make_subplots(rows=2, cols=2, \n",
    "                    subplot_titles=(\"Faithfulness vs Correctness\",\n",
    "                                    \"Relevancy vs Correctness\",\n",
    "                                    \"Faithfulness vs Semantic Similarity\",\n",
    "                                    \"Correctness vs Semantic Similarity\"))\n",
    "\n",
    "# Plot 1\n",
    "fig1 = px.scatter(df, \n",
    "                  y='faithfulness', \n",
    "                  x='answer_correctness', \n",
    "                  color='retrieval_type', \n",
    "                #   size='answer_relevancy',\n",
    "                  hover_name=df.index,\n",
    "                  color_discrete_sequence=px.colors.qualitative.Set1)\n",
    "for trace in fig1.data:\n",
    "    fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "# Plot 2\n",
    "fig2 = px.scatter(df,\n",
    "                  y='answer_relevancy', \n",
    "                  x='answer_correctness', \n",
    "                  color='retrieval_type',\n",
    "                  hover_name=df.index,\n",
    "                  color_discrete_sequence=px.colors.qualitative.Set1)\n",
    "for trace in fig2.data:\n",
    "    fig.add_trace(trace.update(showlegend=False), row=1, col=2)\n",
    "\n",
    "# Plot 3\n",
    "fig3 = px.scatter(df, \n",
    "                  y='faithfulness',\n",
    "                  x='semantic_similarity',                  \n",
    "                  color='retrieval_type',\n",
    "                  hover_name=df.index,\n",
    "                  color_discrete_sequence=px.colors.qualitative.Set1)\n",
    "for trace in fig3.data:\n",
    "    fig.add_trace(trace.update(showlegend=False), row=2, col=1)\n",
    "\n",
    "# Plot 4\n",
    "fig4 = px.scatter(df, \n",
    "                  y='answer_correctness',\n",
    "                  x='semantic_similarity', \n",
    "                  color='retrieval_type',\n",
    "                  hover_name=df.index,\n",
    "                  color_discrete_sequence=px.colors.qualitative.Set1)\n",
    "for trace in fig4.data:\n",
    "    fig.add_trace(trace.update(showlegend=False), row=2, col=2)\n",
    "\n",
    "# Set axis limits and titles for each subplot automatically\n",
    "axes_info = [\n",
    "    (\"Faithfulness\",\"Correctness\"),\n",
    "    (\"Relevancy\", \"Correctness\"),\n",
    "    (\"Faithfulness\", \"Semantic Similarity\"),\n",
    "    (\"Correctness\",\"Semantic Similarity\")   \n",
    "]\n",
    "\n",
    "for i in range(2):  # Rows\n",
    "    for j in range(2):  # Columns\n",
    "        y_axis, x_axis = axes_info[i * 2 + j]\n",
    "        fig.update_xaxes(title_text=x_axis.replace('_', ' ').capitalize(), \n",
    "                         range=[0, 1.05], dtick=0.1, gridwidth=1, row=i + 1, col=j + 1)\n",
    "        fig.update_yaxes(title_text=y_axis.replace('_', ' ').capitalize(), \n",
    "                         range=[0, 1.05], dtick=0.1, gridwidth=1, row=i + 1, col=j + 1)\n",
    "\n",
    "# Show the plot\n",
    "fig.update_layout(height=800, width=800, \n",
    "                  legend=dict(\n",
    "                    orientation=\"h\",  # Horizontal legend\n",
    "                    yanchor=\"bottom\",\n",
    "                    y=0.475,  # Position just below the title\n",
    "                    xanchor=\"center\",\n",
    "                    x=0.5  # Center the legend\n",
    "                    ),\n",
    "                  title_text=\"GraphRAG w/ RAGAS Metrics\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14154e5bf0da41ab94bc50d10b13c815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='670px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize Graph\n",
    "from neo4j import GraphDatabase\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "\n",
    "# TODO: Chunk ids should not be hardcoded.  \n",
    "cypher = \"MATCH (n:Document)<-[r]->(c:Chunk)<-[s]->(e) WHERE c.id in ['df99f8192bf2961d93f8fa02eb32337088dbeffb', 'f73ae203cb7d3238826460d93b4dcbef24801c62','3a73ea9f64943113b439136645a4e244a6e37935','8eee3b357209bc21f61d633156b9d00b829ddc73']  RETURN n,r,c,s,e LIMIT 1000\"\n",
    "\n",
    "showGraph(cypher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "\n",
    "**Graph Search** \n",
    "  - **Use Cases**: Good for inherent relationships and connections between nodes in the graph database. Relationship-Focused. \n",
    "  - However, the graph response is subject to how well the LLM (i.e Gemini) translate the query into a cypher statement since the graph retrieval for this Neo4j llm-graph-builder repo requires the node and label to match cypher query in order to extract the information under the description attribute of the retrieved node.\n",
    "\n",
    "**Vector Search** \n",
    "  - **Use Cases**: Suitable for NLP tasks like retrieving documents or chunks relevant to a user's query based on context or topic rather than specific keywords\n",
    "Uses embeddings to capture the semantic meaning of nodes or documents based on similarity (i.e cosine, euclidian). \n",
    "  - **Embedding Based**: Represents entities or text as vectors in a high-dimensional space. The similarity between vectors is computed using distance metrics like cosine similarity\n",
    "  - **Semantic Search**: Focuses on the meaning of the text rather than exact term matching. Allowing it to retrieve relevant information even if exact keywords aren't present.\n",
    "   - **Example**: Finding documents related to \"cerebral arteries\" even if the desired term \"anterior inferior cerebellar artery\" is not mentioned explicitly\n",
    "  - **Speed and Scalability**: Effective for large datasets where relationships may not be explicitly defined but where semantic meaning is crucial\n",
    "  - However, it can assume the knowledge graph has additional information beyond the ingested data, when the aggregated embeddings of retrieved documents is translated into human readable response text.\n",
    "\n",
    "**Hybrid (Vector + Keyword) Search**\n",
    "  - **Vector Search**: This utilizes embeddings (numerical representations of words or phrases) to capture semantic meaning. It excels at finding relevant content based on similarity rather than exact matches. Use cases include:\n",
    "    - Finding contextually relevant documents.\n",
    "    - Identifying similar concepts or entities.\n",
    "  - **Keyword Search**: This traditional approach matches exact words or phrases within the text. It's efficient for retrieving specific information quickly. Use cases include:\n",
    "    - Fetching documents containing specific terms.\n",
    "    - Querying for precise data points.\n",
    "  - **Hybrid Search**: This combines both methods, allowing the system to consider both semantic relevance and exact matches. It can improve recall and precision by:\n",
    "    - Prioritizing results based on semantic similarity while also ensuring relevant keyword matches are included.\n",
    "    - Offering a more nuanced understanding of user queries that may be ambiguous or context-dependent.\n",
    "  \n",
    "**Hybrid Cypher Retrieval**: \n",
    "  - Combines graph search on top of hybrid (vector + keyword) search methodologies, leveraging the strengths of each approach to enhance retrieval more accurate to the ingested knowledge graph.\n",
    "  - Incorporates both the relationship-based filtering of graph search on top of semantic similarity assessment of vector search and exact similarity of full-text search via hybrid retrieval.\n",
    "  - Allows users to retrieve results based on exact relationships (from graph search) while also considering the semantic relevance from vector search\n",
    "  - **Use Cases**: Best suited for complex queries where both the structural relationships and semantic content are important, such as in knowledge graphs or when navigating large datasets with interrelated concepts\n",
    "  - **Example**: Finding not only documents about \"anterior inferior cerebellar artery\" but also documents that are semantically similar while considering the relationships between entities in the graph, like clinical guidelines or related anatomical structures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
